{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN24BXTgVZliJ/Q85m6gvhY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/b3yotch/Creative_upaay/blob/main/Creative_Upaay_semantic_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ajEChdjOhU9t",
        "outputId": "96f50b49-580e-4fdc-a514-042e8b624070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.12.34-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.39)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl.metadata (438 bytes)\n",
            "Collecting llama-index-cli<0.5,>=0.4.1 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.34 (from llama-index)\n",
            "  Downloading llama_index_core-0.12.34.post1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.3.38-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.76.2)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (3.11.15)\n",
            "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.2.18)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (3.4.2)\n",
            "Collecting tiktoken>=0.7.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.17.2)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.20-py3-none-any.whl.metadata (914 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.7)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.21-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (1.20.0)\n",
            "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (4.3.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Collecting llama-cloud-services>=0.6.21 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.12.34-py3-none-any.whl (7.0 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.12.34.post1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_llms_openai-0.3.38-py3-none-any.whl (23 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading banks-2.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_parse-0.6.21-py3-none-any.whl (4.9 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_cloud_services-0.6.21-py3-none-any.whl (37 kB)\n",
            "Downloading llama_cloud-0.1.19-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.6/263.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, python-dotenv, PyPDF2, pypdf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, faiss-cpu, colorama, typing-inspect, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, griffe, bs4, nvidia-cusolver-cu12, llama-cloud, dataclasses-json, banks, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed PyPDF2-3.0.1 banks-2.1.2 bs4-0.0.2 colorama-0.4.6 dataclasses-json-0.6.7 dirtyjson-1.0.8 faiss-cpu-1.11.0 filetype-1.2.0 griffe-1.7.3 llama-cloud-0.1.19 llama-cloud-services-0.6.21 llama-index-0.12.34 llama-index-agent-openai-0.4.7 llama-index-cli-0.4.1 llama-index-core-0.12.34.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.38 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.21 marshmallow-3.26.1 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pypdf-5.4.0 python-dotenv-1.1.0 striprtf-0.0.26 tiktoken-0.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers faiss-cpu langchain llama-index nltk PyPDF2 requests bs4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import PyPDF2\n",
        "from io import BytesIO\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "F15pgKVNhyzW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents(sources):\n",
        "    \"\"\"\n",
        "    Load documents from  sources ( web URLs).\n",
        "\n",
        "    sources: List of dictionaries with 'path' and 'type' keys\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    for source in sources:\n",
        "        path = source['path']\n",
        "        source_type = source['type']\n",
        "\n",
        "        try:\n",
        "\n",
        "            if source_type == 'url':\n",
        "                content = extract_text_from_url(path)\n",
        "                documents.append({\"content\": content, \"source\": path})\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {path}: {e}\")\n",
        "\n",
        "    return documents"
      ],
      "metadata": {
        "id": "EqTraERyjn60"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_url(url):\n",
        "    \"\"\"Extract text and title from a web page.\"\"\"\n",
        "    text = \"\"\n",
        "    title = \"Untitled\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # Get the title tag or fallback to <h1> or other header\n",
        "            if soup.title and soup.title.string:\n",
        "                title = soup.title.string.strip()\n",
        "            else:\n",
        "                h1 = soup.find('h1')\n",
        "                if h1:\n",
        "                    title = h1.get_text(strip=True)\n",
        "\n",
        "            # Extract article or body text\n",
        "            article = soup.find('article') or soup.find('body')\n",
        "            if article:\n",
        "                for script in article([\"script\", \"style\"]):\n",
        "                    script.extract()\n",
        "                text = article.get_text(separator=\"\\n\")\n",
        "            else:\n",
        "                text = soup.get_text(separator=\"\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting from URL {url}: {e}\")\n",
        "\n",
        "    return title, text\n"
      ],
      "metadata": {
        "id": "p-NgTYjRnNDM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_sources():\n",
        "    \"\"\"Process sources for the knowledge base.\"\"\"\n",
        "    sources = [\n",
        "        {\"path\":\"https://medium.com/@jh.baek.sd/chroma-vs-faiss-a-comparative-analysis-527a4f3c8fb\", \"type\":\"url\"},\n",
        "        {\"path\": \"https://medium.com/analytics-vidhya/what-is-rnn-a157d903a88\", \"type\": \"url\"},\n",
        "        {\"path\": \"https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\", \"type\": \"url\"},\n",
        "        {\"path\":\"https://vajiramandravi.com/upsc-exam/rafale-fighter-jet/\", \"type\":\"url\"},\n",
        "        {\"path\":\"https://www.geeksforgeeks.org/implementing-the-adaboost-algorithm-from-scratch/\", \"type\":\"url\"},\n",
        "        {\"path\":\"https://medium.com/civic-skunk-works/a-blinking-red-light-for-the-economy-fcf621189ed5\", \"type\":\"url\"},\n",
        "        {\"path\":\"https://www.autosport.com/f1/news/how-does-a-formula-1-car-work-wings-diffusers-and-more-explained-4982275/4982275/\", \"type\":\"url\"},\n",
        "        {\"path\":\"https://www.geeksforgeeks.org/model-context-protocol-mcp/\", \"type\":\"url\"},\n",
        "        {\"path\":\"https://medium.com/@tahirbalarabe2/what-is-prompt-engineering-rag-cot-react-dsp-explained-0aa0a9bd0a90\", \"type\":\"url\"},\n",
        "        {\"path\":\"https://www.geeksforgeeks.org/box-cox-transformation-using-python/\", \"type\":\"url\"},\n",
        "        {\"path\":\"https://www.geeksforgeeks.org/bernoulli-distribution-in-business-statistics-mean-and-variance/\", \"type\":\"url\"},\n",
        "        {\"path\":\"https://www.ibm.com/think/topics/fine-tuning\", \"type\":\"url\"},\n",
        "        {\"path\":\"https://www.ibm.com/think/topics/ensemble-learning\", \"type\":\"url\"},\n",
        "        {\"path\":\"https://www.geeksforgeeks.org/understanding-of-lstm-networks/\", \"type\":\"url\"},\n",
        "\n",
        "        {\"path\":\"https://www.geeksforgeeks.org/what-is-crewai/\", \"type\":\"url\"},\n",
        "\n",
        "\n",
        "        ]\n",
        "\n",
        "    documents = load_documents(sources)\n",
        "\n",
        "\n",
        "    return documents"
      ],
      "metadata": {
        "id": "2ocJSpT9moUg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt')\n",
        "documents = process_sources()\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    \"\"\"Convert POS tag to wordnet format for lemmatizer\"\"\"\n",
        "    if tag.startswith(\"J\"):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith(\"V\"):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith(\"N\"):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith(\"R\"):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "def preprocess_text(item):\n",
        "    \"\"\"Cleans and preprocesses AI article content\"\"\"\n",
        "    source_url = item[\"source\"]\n",
        "    text = item[\"content\"][1].lower()\n",
        "    title=item[\"content\"][0]\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "\n",
        "    cleaned_tokens = [\n",
        "        lemmatizer.lemmatize(word, get_wordnet_pos(tag))\n",
        "        for word, tag in pos_tags\n",
        "        if word not in stop_words and word.isalpha()\n",
        "    ]\n",
        "\n",
        "    cleaned_text = \" \".join(cleaned_tokens)\n",
        "    return {\"source\": source_url,\"title\":title, \"cleaned_text\": cleaned_text}\n",
        "\n",
        "# Applying preprocessing in parallel\n",
        "cleaned_data = []\n",
        "with ThreadPoolExecutor(max_workers=6) as executor:\n",
        "    results = list(tqdm(executor.map(preprocess_text, documents), total=len(documents), desc=\"Preprocessing AI Articles\"))\n",
        "    cleaned_data.extend(results)\n",
        "\n",
        "\n",
        "with open(\"cleaned_ai_articles.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(cleaned_data, f, indent=2)\n",
        "\n",
        "# Preview\n",
        "print(cleaned_data[:2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLnaYYg6cmFE",
        "outputId": "83ac9390-d475-4d37-c782-4c3c20d46245"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Preprocessing AI Articles: 100%|██████████| 15/15 [00:02<00:00,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'source': 'https://medium.com/@jh.baek.sd/chroma-vs-faiss-a-comparative-analysis-527a4f3c8fb', 'title': 'Chroma vs FAISS: A Comparative Analysis | by ZIRU | Medium', 'cleaned_text': 'story chroma v faiss comparative analysis win unpack feature chroma faiss ziru follow min read aug share photo caspar camille rubin unsplash compare chroma faiss involves examine feature use case performance c hroma vector store embeddings database design make easy build ai application embeddings main feature include easy setup chroma design run machine instal chroma simple run pip install command local development chroma build run seamlessly local development make easy prototype ai application design ai workload chroma build handle modern ai workload make good fit application heavily utilize embeddings f aiss hand library develop facebook efficient similarity search clustering dense vector feature include efficiency faiss design efficient similarity search crucial application involve semantic search open source faiss library open source allow developer examine modify distribute source code standalone vector database faiss'}, {'source': 'https://medium.com/analytics-vidhya/what-is-rnn-a157d903a88', 'title': 'Recurrent Neural Networks — Complete and In-depth | by Tejas T A | Analytics Vidhya | Medium', 'cleaned_text': 'recurrent neural network complete tejas follow min read dec listen share rnn recurrent neural network type deep learning neural net remember input sequence store memory state predict future abstract study explore effectiveness recurrent neural network rnns predict customer behavior compare performance traditional machine learning model increase availability temporal data environment present unique opportunity improve customer behavior prediction leverage model capable capture sequential dependency use instacart market basket analysis dataset contain record customer purchase time case study evaluate prediction accuracy model like simple rnn long memory lstm gate recurrent unit gru traditional model logistic regression random forest serve benchmark comparison result indicate model outperform traditional model especially capture complex temporal pattern customer behavior use key evaluation metric accuracy precision recall demonstrate rnns provide robust framework understand predict customer action finding practical implication business look optimize marketing strategy personalize customer experience predict purchase pattern effectively future work may explore improvement integrate attention mechanism transformer model enhance predictive performance introduction background significance research today rapidly evolve landscape ability predict customer behavior become critical asset business company anticipate purchasing preference action customer well position personalize recommendation optimize inventory management design effective marketing strategy traditional machine learning model logistic regression decision tree widely use customer behavior prediction however model often struggle capture temporal dynamic inherent customer interaction lead suboptimal prediction scenario sequential data play key role rise deep learning particularly recurrent neural network rnns grow interest leverage model address limitation traditional approach rnns advanced variant long memory lstm gate recurrent unit gru design process sequential data make capture temporal dependency customer purchase pattern research explore application rnns predict customer behavior compare performance traditional machine learning model highlight advantage model statement problem despite potential rnns capture sequential pattern customer behavior remain limited empirical evidence compare performance traditional model application primary research problem study address determine whether rnns significantly outperform traditional machine learning model predict customer behavior particularly scenario involve sequential purchase data additionally study aim identify specific benefit limitation use rnns traditional method hypothesis hypothesize recurrent neural network rnns due ability model temporal dependency outperform traditional machine learning model predict customer behavior specifically model like lstm gru expect show high accuracy precision overall predictive performance apply customer purchase data objective study objective study follow evaluate effectiveness rnn model simple rnn lstm gru predict customer behavior use instacart market basket analysis dataset compare predictive performance rnns traditional machine learning model logistic regression random forest etc dataset analyze advantage rnns capture sequential pattern customer data implication business strategy identify potential limitation rnn model explore avenue improve prediction accuracy incorporation attention mechanism transformer model literature review overview exist research customer behavior prediction customer behavior prediction central focus field retail analytics decade traditional model primarily rely static feature customer demographic purchase history product attribute predict future action study researcher like verbeke et al neslin et al demonstrate effectiveness method variety business application include customer churn prediction product recommendation however increase temporal data availability new approach emerge model sequential customer behavior effectively recent research emphasize importance capture nature customer interaction study like fader hardie introduce model incorporate recency frequency monetary value rfm account temporal factor customer transaction however model often rely handcrafted feature limit inability capture complex sequential dependency time open door advanced technique include base deep learning discussion traditional machine learning model limitation traditional machine learn model logistic regression decision tree random forest method customer behavior prediction model highly interpretable widely use various industry due ability model categorical continuous variable efficiently example harford et al demonstrate effectiveness decision model predict customer churn response marketing campaign however despite utility traditional model face significant limitation come handle sequential data model operate assumption customer interaction independent ignore temporal dependency often crucial accurate prediction customer behavior prediction past event order product purchase direct impact future behavior limitation prompt researcher explore advanced approach account data moreover traditional model typically require manual feature engineering domain expert must define feature capture temporal pattern approach effective may fail capture complex relationship present data consequently researcher turn deep learning model capable learn temporal dependency directly data without need extensive feature engineering introduction rnns advantage handle temporal dependency recurrent neural network rnns design address shortcoming traditional machine learning model handle sequential data introduce rumelhart et al rnns allow information persist across time step make ideal task order event crucial customer behavior prediction mean rnns model progression customer purchase interaction preference time essential accurately forecasting future action advanced variant rnns long memory lstm network hochreiter schmidhuber gate recurrent unit gru cho et develop address vanishing gradient problem standard rnns face model allow capture dependency data make particularly effective situation event distant past influence present action customer purchase decision influence purchase make several month ago several study explore application rnns customer behavior prediction example zhang et al demonstrate lstm network outperform traditional model predict customer churn leverage sequential nature customer interaction similarly liu et al show gru model able effectively model purchase sequence lead improve product recommendation accuracy finding underscore potential rnns capture temporal pattern traditional model often miss neslin et verbeke et leverage sequential nature customer data rnns able predict future behavior accurately also provide deep insight dynamic customer interaction make valuable tool business seek personalize customer experience optimize marketing strategy predict future behavior base past action methodology description dataset dataset use study instacart market basket analysis dataset contain rich set transactional data popular grocery delivery service include information million online grocery order customer customer place multiple order allow dataset capture sequential purchasing behavior time dataset consist several table join use common set key order contains detail order include order id customer id order sequence first order second order etc day week hour day order place product include information product id product name category order product table link order product contain provide quantity product purchase give order customer information relate customer user id aisle department product classification broad category dataset allow construction sequence customer purchase time make highly suitable evaluate temporal model like recurrent neural network rnns provide insight customer behavior pattern product preference timing order essential behavior prediction data preprocessing step feed data predictive model several preprocessing step require convert raw dataset form use rnns traditional machine learning model primary step include step merging data table explanation instacart dataset spread across multiple table order product need merge table create unified dataset contain relevant information customer order product purchase merge dataset allow u create sequence purchase customer crucial feed model code import panda pd load datasets order product merge order get product detail order merge order merge product get name category product merge merge product display merged dataset print explanation use function join table use common key like result dataset contain column like use create sequential data step create sequence explanation rnns require sequential data input customer need group order arrange chronological order create sequence product purchase sequence represent list product buy several order serve input model code create sequence product purchase customer list display first sequence print explanation use groupby group dataset customer use apply list create list product customer base order history result sequence product id customer form input rnn step padding sequence explanation rnn model expect input sequence length however customer place number order ensure uniformity pad sequence fixed length sequence short length pad zero long sequence truncate code import set maximum length sequence order pad sequence length display padded sequence print explanation function pad sequence specify maximum length maxlen sequence short maximum length pad zero pad post argument ensure pad apply end sequence step ensure sequence equal length necessary train rnn model step split data explanation evaluate model performance need split dataset training validation test set training set use fit model validation set help hyperparameters test set use assess model performance unseen data code import split dataset training test set split training set training validation set display shape datasets print set size print set size print set size explanation use first split dataset training test set split training set training validation set test size set total dataset validation set training data ensure separate datasets model training tuning final evaluation step scale data need explanation dataset contain numerical feature like time day order frequency feature may need scale uniform range step ensure feature large range disproportionately affect model learn process code import minmaxscaler extract scale feature order scaler minmaxscaler display scaled time feature print explanation minmaxscaler use scale feature step ensure feature large value dominate learning process help improve model performance detailed explanation rnn architecture rnn explanation simple rnn basic form recurrent neural network simple rnn information pass hidden state one time step next hidden state time step depend input step also hidden state previous time step enable network retain memory previous input allow model sequential data architecture simple rnn describe follow time step input xt process along hidden state previous time step hidden state ht update use activation function like tanh relu output generate base update hidden state however simple rnns suffer vanish gradient problem make difficult retain information long sequence rumelhart hinton williams mainly use short sequence dependency critical rnn architecture diagram imagine looping structure time step receive input output hidden state hidden state pass forward next step sequence illustration simple rnn architecture input xt hide state pass one step next output time step base hidden state import sequential import simplernn dense define simple rnn model model sequential simplernn dense output layer compile model display model summary explanation code create simple rnn hidden unit input shape sequence length number feature output layer single neuron sigmoid activation function commonly use binary classification memory lstm explanation long memory lstm network advanced type rnn design overcome vanishing gradient problem simple rnns lstms capable learn dependency use special architecture include three gate input gate forget gate output gate gate control flow information network allow model retain discard information necessary hochreiter schmidhuber architecture lstm describe follow input gate determines information input add cell state forget gate decides information previous cell state discard output gate determines part cell state output hidden state gate mechanism allow lstms capture dependency make effective task speech recognition text generation forecasting lstm architecture diagram contrast simple rnn lstm unit contain memory cell ct addition hidden state three gate manage information flow within cell simplified diagram input xt cell state preserve memory hidden state pass one step next import lstm import lstm dense import adam define lstm model model sequential lstm dense compile model display model summary explanation example build lstm model hidden unit input shape still since lstm also expect sequential data lstm network powerful simple rnns task involve long sequence data gated recurrent unit gru explanation gated recurrent unit gru simplified version lstm combine forget input gate single update gate reduce complexity model retain many benefit lstms ability capture dependency grus tend perform similarly lstms computationally faster due simpler structure cho et architecture gru describe follow update gate determine much past information need pass future reset gate determine much past information forget hidden state update base gate allow gru capture dependency gru architecture diagram like lstms grus manage flow information gating mechanism however few gate separate cell state rely solely hidden state diagram overview input xt hide state update base update reset gate import gru define gru model model sequential gru dense compile model display model summary explanation define gru model hidden unit input shape grus often prefer computational efficiency concern faster lstms may perform similarly many task summary rnn architecture simple rnn work short sequence struggle dependency due vanish gradient problem lstm advanced architecture memory cell gate handle dependency make highly effective sequential data gru simplified version lstm few gate offer fast computation maintain performance long sequence architecture suit different task depend complexity data length sequence training procedure explanation training rnns include backpropagation time train recurrent neural network rnn include advanced architecture like lstm gru follow procedure somewhat similar traditional neural network main difference error propagate time process call backpropagation time bptt allow rnns learn sequential data let break key aspect training procedure pas forward pas input sequence process step step rnn time step model take input hidden state previous time step process generate output yt updated hidden state rnn represent w u weight matrix input hidden state respectively f activation function tanh relu b bias term hidden state previous time step current input time forward pas continue every time step sequence final output yt produce loss calculation end forward pas model calculate loss use appropriate loss function binary classification task mean squared error regression task loss measure far predict output yt actual target yt true sequence length total loss l calculate sum individual loss time step backpropagation time bptt traditional neural network error propagate backward layer update weight rnns process extend time call backpropagation time bptt work step error propagation error propagate backward time step loss final time step first propagate update weight last time step error previous time step use adjust hidden state weight early time step step weight update gradient loss respect weight compute time step weight matrix w input u hide state update require apply chain rule calculus propagate error across layer network across time well gradient key challenge bptt vanish gradient problem gradient shrink propagate backward make hard learn dependency lstms grus design mitigate problem use gate regulate flow information gradient bptt process time step compute loss propagate gradient backward hidden state update weight time step b move back time step propagate gradient update weight base loss time step c continue process time step process update weight matrix use gradient step optimizer gradient descent calculate gradient backpropagation optimizer use update model parameter weight bias commonly used optimizers training rnns adam stochastic gradient descent sgd adam optimizer optimizer adjust learning rate parameter base history gradient make effective complex architecture like rnns stochastic gradient descent sgd case sgd use especially simpler architecture model train small learning rate however adam generally prefer rnns due adaptive nature optimizer update weight w u bias b accord learning rate calculated gradient gradient descent update rule η learn rate gradient loss function respect weight training batch improve efficiency rnns usually train batch rather process one sequence time mean multiple sequence process parallel average loss across batch use update model weight training batch help stabilize gradient update make training process faster epochs epoch refers one complete pas entire training dataset training process typically run multiple epoch ensure model learn effectively epoch model performance evaluate validation set check overfitting underfitting lstm show train model use batch multiple epochs history evaluate model test set print loss test accuracy evaluation metric accuracy precision recall evaluation metric play crucial role assess well rnn model perform especially deal classification task detailed explanation metric accuracy definition accuracy straightforward evaluation metric measure proportion correctly classify instance positive negative total number tp true positive correctly predict positive instance tn true negative correctly predict negative instance fp false positive incorrectly predict positive instance fn false negative incorrectly predict negative instance explanation accuracy useful class balance mislead case imbalanced datasets example data negative model predict instance negative accuracy might still even though model completely fail predict positive class code calculate accuracy use keras metric model compilation accuracy also calculate automatically use print accuracy precision definition precision measure many predicted positive instance actually positive focus quality positive prediction make model explanation precision especially important cost false positive high instance spam detection precision crucial false positive mark legitimate email spam cause significant inconvenience code import predict class label test set calculate precision precision print precision recall sensitivity true positive rate definition recall measure many actual positive instance correctly predict model focus ability model identify positive instance explanation recall crucial miss positive instance costly example medical diagnosis low recall could mean miss detect disease patient could severe consequence code import calculate recall recall print recall definition harmonic mean precision recall provide single metric balance precision recall make useful need find balance explanation particularly helpful class distribution imbalanced give balanced view well model performs false positive false negative high mean model high precision high recall make good metric many classification problem code import calculate print receiver operating characteristic area curve definition roc curve graphical representation plot true positive rate recall false positive rate various threshold level auc area curve measure entire area underneath roc curve commonly use metric evaluate performance binary classifier true positive rate tpr recall calculate false positive rate fpr calculate explanation roc curve show well model distinguish class decision threshold change auc score range score indicates perfect classification score indicates model good random guessing auc model discrimination capacity distinguish positive negative class auc model perfectly distinguish positive negative class auc particularly useful imbalanced datasets accuracy might reflect model true performance code import predict class probability test set calculate score print visualize roc curve import plt import generate roc curve data fpr tpr threshold plot roc curve fpr tpr lstm positive rate positive rate curve result presentation experimental result presentation experimental result involve showcasing performance rnn model simple rnn lstm gru well traditional machine learning model customer behavior prediction task section highlight key comparison term accuracy precision recall alongside visualization provide intuitive understanding model performance setup evaluate following model instacart market basket analysis dataset traditional machine learning model logistic regression random forest recurrent neural network rnn model simple rnn lstm gru dataset split training validation test set model train use feature evaluate use test set ensure fair comparison metric comparison table table summarize key evaluation metric model key insight lstm model outperform traditional model rnn architecture across evaluation metric high accuracy gru performs similarly lstm slightly less accurate accuracy traditional machine learn like random forest logistic regression show lower overall performance particularly recall indicate limitation capture sequential dependency simple rnn show competitive performance fail match performance lstm gru due limitation handle dependency visualize model performance roc curve roc curve model provide visual comparison ability distinguish positive negative class across different threshold see chart lstm high area curve indicate superior performance curve curve demonstrate precision recall lstm show best balance make effective model task confusion matrix confusion matrix model highlight model make mistake particularly term false positive false negative lstm gru demonstrate few misclassifications compare traditional model simple rnn visualizing loss accuracy epochs training validation accuracy lstm gru show consistent improvement accuracy epoch indicate model learn effectively without overfitting simple rnn show slow convergence compare lstm gru training validation loss lstm low loss training validation indicate model generalize well gru also show low loss slightly high compare lstm whereas simple rnn show high loss value suggest struggle long sequence interpretation result result indicate model particularly lstm gru effective capture sequential nature customer purchase data lead good prediction customer behavior traditional model like logistic regression random forest unable model temporal dependency effectively lead lower performance metric lstm stand best performing model likely due ability capture dependency use memory cell make powerful tool type data recommendation base result base experimental result recommend lstm primary model business look predict customer behavior temporal data superior performance across metric make ideal application require high predictive accuracy gru alternative case computational efficiency important perform nearly well lstm few parameter faster training time traditional model like random forest consider simpler task temporal relationship crucial discussion analysis rnns perform well recurrent neural network rnns particularly advanced variant like lstm gru demonstrate superior performance traditional model logistic regression random forest customer behavior prediction several key factor explain rnns outperform traditional model capture temporal dependency rnns design process sequential data make ideal task like customer behavior prediction order past purchase play crucial role predict future action traditional model lack ability capture temporal dependency essential understand customer purchase pattern time memory lstms grus lstm gru architecture allow model retain information early time step effectively capture relationship especially valuable predict customer behavior past purchasing habit seasonal recur purchase influence future decision traditional model treat instance independent fail incorporate dependency dynamic complex data rnns excel learn dynamic sequential data pattern customer purchasing data inherently complex individual behavior change time contrast traditional model struggle relationship less effective handle evolve nature customer behavior feature engineering traditional model often rely extensive feature engineering capture sequential pattern contrast rnns especially lstms grus learn relevant feature directly data reduce need manual feature engineering discussion limitation potential improvement despite strong performance rnns lstms grus limitation could impact effectiveness certain context training complexity training model computationally intensive particularly large datasets rnns especially lstms grus high training complexity compare traditional model due backpropagation time bptt algorithm lead longer train time case may require computational resource gradient although lstms grus design mitigate vanishing gradient problem still affect model particularly process long sequence could limit ability rnns retain dependency effectively data requirement rnn model require substantial amount sequential data generalize well data sparse noisy performance may degrade traditional model may perform good situation limited data sequential dependency weak potential overfitting rnn model due complexity may prone overfitting particularly train small datasets regularization technique like dropout employ mitigate risk remain challenge potential improvement attention mechanism incorporate attention mechanism could improve performance rnns allow model focus specific part sequence relevant prediction would enhance ability capture dependency effectively transformer model transformer show outperform rnns many sequential task due parallelizable architecture mechanism future work incorporate transformer customer behavior prediction could improve accuracy training efficiency data augmentation improving data quality data augmentation technique create synthetic sequence could enhance performance rnn model especially available dataset limit implication business customer behavior prediction accurately predict customer behavior significantly impact business especially retail service result study suggest rnn model especially lstms grus provide significant business advantage term customer behavior analysis personalized marketing predict customer preference purchase behavior business deliver personalized marketing campaign could increase customer engagement lead high conversion rate example business offer targeted discount recommend product base predicted future purchase improve customer satisfaction loyalty inventory management accurate customer behavior prediction enable business optimize inventory management anticipate customer demand business better manage stock level reduce overstock stockouts optimize supply chain operation customer retention rnn model help identify customer likely churn leave service analyze past interaction behavior business use information implement retention strategy offer personalized incentive customer revenue optimization leverage prediction rnn model business optimize pricing strategy product recommendation could lead increase average order value high revenue per customer improved profitability improve use model effectively capture customer behavior business make decision help develop precise marketing strategy enhance product offering improve customer service conclusion application rnn model particularly lstm gru architecture represent powerful tool business aim predict influence customer behavior address limitation leverage future advancement like attention mechanism business enhance ability understand respond customer need conclusion summary key finding study explore effectiveness various machine learning model particularly recurrent neural network rnns predict customer behavior use instacart market basket analysis dataset key finding follow model especially lstm gru outperform traditional model logistic regression random forest predict customer behavior ability capture temporal dependency handle memory learn sequential data make well suit task lstm emerge model demonstrate high accuracy precision recall score architecture include memory cell gate mechanism allow retain utilize information customer purchase sequence effectively gru show similar performance lstm though slightly low accuracy slightly faster training process make good alternative computational efficiency priority traditional model useful certain task struggle handle sequential nature data result low accuracy recall fail capture intricate pattern customer purchasing behavior time simple rnns although capable handle sequential data less effective lstm gru due limitation vanish gradient problem reduced ability capture dependency suggestion future work finding study underscore power rnn model predict customer behavior several area improvement future exploration identify incorporating attention mechanism one key limitation rnns even advanced form lstm gru reliance processing sequence step step dilute importance critical time step integrate attention mechanism model focus relevant part sequence potentially improve performance attention allow model weigh different part input sequence differently give high importance critical input prediction task explore transformer model transformer architecture revolutionize natural language processing could offer significant improvement customer behavior prediction transformer highly parallelizable capture dependency sequence efficiently rnns test transformer customer behavior prediction task could reveal new opportunity enhance predictive accuracy reduce train time hybrid model future work could explore combine strength traditional machine learning model approach example hybrid model could use traditional method initial feature extraction rnns sequence modeling leverage strength approach prediction enhance model make prediction customer behavior personalized product recommendation live session could unlock significant value business would require improvement model efficiency deployment strategy potential impact customer satisfaction engagement would substantial transfer learn customer behavior applying transfer learn technique model train large customer datasets specific business industry could improve generalizability applicability model broad range use case data augmentation handle miss data case customer behavior data sparse incomplete employ data augmentation technique advanced method handle miss data could improve model performance robustness incorporate external data enrich customer behavior prediction model incorporate external data source economic indicator seasonal trend social medium activity could provide comprehensive insight improve predictive power model summary rnns especially lstm gru demonstrate strong predictive capability numerous avenue enhance performance applicability future integrate technique like attention mechanism transformer model business improve ability predict influence customer behavior drive good outcome marketing sale customer retention reference lecun bengio hinton deep learning nature vol pp may graf mohamed hinton speech recognition deep recurrent neural network proc ieee int conf speech signal process icassp vancouver bc canada may pp bahdanau cho bengio neural machine translation jointly learn align translate proc int conf learn representation iclr san diego ca usa may sutskever vinyals le sequence sequence learn neural network proc int conf neural inf process syst nip montreal qc canada pp hochreiter schmidhuber long memory neural computation vol pp glorot bordes bengio deep sparse rectifier neural network proc int conf artif intell stat aistats fort lauderdale fl usa apr pp cho et learn phrase representation use rnn statistical machine translation proc conf empirical method natural language process emnlp doha qatar pp chung gulcehre cho bengio empirical evaluation gated recurrent neural network sequence modeling proc nip workshop deep learning montreal qc canada mikolov karafiát burget cernocký khudanpur recurrent neural network base language model proc annu conf int speech commun assoc interspeech makuhari japan pp mnih hinton scalable hierarchical distribute language model proc nip vancouver bc canada pp schuster paliwal bidirectional recurrent neural network ieee trans signal process vol pp hinton osindero teh fast learning algorithm deep belief net neural comput vol pp july krizhevsky sutskever hinton imagenet classification deep convolutional neural network proc nip lake tahoe nv usa pp glorot bengio understand difficulty train deep feedforward neural network proc int conf artif intell stat aistats sardinia italy may pp kim convolutional neural network sentence classification proc emnlp doha qatar pp goodfellow et generative adversarial net proc nip montreal qc canada pp collobert weston bottou karlen kavukcuoglu kuksa natural language processing almost scratch mach learn re vol pp'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_ai_article(cleaned_text):\n",
        "    \"\"\"\n",
        "    Classifies a cleaned text into ML/DL/GenAI/NLP/CV categories.\n",
        "    Multi-label classification based on keyword matching.\n",
        "    \"\"\"\n",
        "    categories = set()\n",
        "    text = cleaned_text.lower()\n",
        "\n",
        "    ml_keywords = [\"regression\", \"classification\", \"supervised\", \"unsupervised\", \"adaboost\",\"Random Forest\", \"ensemble\", \"svm\"]\n",
        "    dl_keywords = [\"neural network\", \"cnn\", \"lstm\", \"rnn\", \"backpropagation\", \"deep learning\"]\n",
        "    genai_keywords = [\"gpt\", \"llm\",\"\", \"generative\", \"chatgpt\",  \"gemini\",\"Anthropic\", \"prompt engineering\",\"vector databases\",\"chroma\",\"faiss\",\"pinecone\",\"MCP\"]\n",
        "    nlp_keywords = [\"nlp\", \"tokenization\", \"transformer\", \"bert\", \"language model\", \"attention\"]\n",
        "    cv_keywords = [\"image\", \"vision\", \"cnn\", \"object detection\", \"segmentation\"]\n",
        "\n",
        "\n",
        "    for word in ml_keywords:\n",
        "        if word in text:\n",
        "            categories.add(\"ML\")\n",
        "            break\n",
        "    for word in dl_keywords:\n",
        "        if word in text:\n",
        "            categories.add(\"DL\")\n",
        "            break\n",
        "    for word in genai_keywords:\n",
        "        if word in text:\n",
        "            categories.add(\"GenAI\")\n",
        "            break\n",
        "    for word in nlp_keywords:\n",
        "        if word in text:\n",
        "            categories.add(\"NLP\")\n",
        "            break\n",
        "    for word in cv_keywords:\n",
        "        if word in text:\n",
        "            categories.add(\"CV\")\n",
        "            break\n",
        "\n",
        "    if not categories:\n",
        "        categories.add(\"Other\")\n",
        "\n",
        "    return list(categories)\n"
      ],
      "metadata": {
        "id": "RLJGFu9Xf1oz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "for item in cleaned_data:\n",
        "    item[\"categories\"] = classify_ai_article(item[\"cleaned_text\"])\n",
        "cat_df = pd.DataFrame(cleaned_data)\n",
        "\n",
        "\n",
        "(cat_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "C1wp8In-f3-C",
        "outputId": "8db9fe79-98e4-4201-8d0f-7b59809530a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              source  \\\n",
              "0  https://medium.com/@jh.baek.sd/chroma-vs-faiss...   \n",
              "1  https://medium.com/analytics-vidhya/what-is-rn...   \n",
              "2  https://medium.com/inside-machine-learning/wha...   \n",
              "3  https://vajiramandravi.com/upsc-exam/rafale-fi...   \n",
              "4  https://www.geeksforgeeks.org/implementing-the...   \n",
              "\n",
              "                                               title  \\\n",
              "0  Chroma vs FAISS: A Comparative Analysis | by Z...   \n",
              "1  Recurrent Neural Networks — Complete and In-de...   \n",
              "2  What is a Transformer?. An Introduction to Tra...   \n",
              "3  Rafale Fighter Jets - All about India's Rafale...   \n",
              "4  Implementing the AdaBoost Algorithm From Scrat...   \n",
              "\n",
              "                                        cleaned_text                categories  \n",
              "0  story chroma v faiss comparative analysis win ...                   [GenAI]  \n",
              "1  recurrent neural network complete tejas follow...  [ML, GenAI, NLP, DL, CV]  \n",
              "2  transformer maxime follow min read jan listen ...  [ML, GenAI, NLP, DL, CV]  \n",
              "3  home rafale aircraft rafale fighter jet india ...                   [GenAI]  \n",
              "4  implement adaboost algorithm scratch last upda...               [ML, GenAI]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7552117d-1ddc-494b-b664-eb3e0fb263b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>title</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://medium.com/@jh.baek.sd/chroma-vs-faiss...</td>\n",
              "      <td>Chroma vs FAISS: A Comparative Analysis | by Z...</td>\n",
              "      <td>story chroma v faiss comparative analysis win ...</td>\n",
              "      <td>[GenAI]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://medium.com/analytics-vidhya/what-is-rn...</td>\n",
              "      <td>Recurrent Neural Networks — Complete and In-de...</td>\n",
              "      <td>recurrent neural network complete tejas follow...</td>\n",
              "      <td>[ML, GenAI, NLP, DL, CV]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://medium.com/inside-machine-learning/wha...</td>\n",
              "      <td>What is a Transformer?. An Introduction to Tra...</td>\n",
              "      <td>transformer maxime follow min read jan listen ...</td>\n",
              "      <td>[ML, GenAI, NLP, DL, CV]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://vajiramandravi.com/upsc-exam/rafale-fi...</td>\n",
              "      <td>Rafale Fighter Jets - All about India's Rafale...</td>\n",
              "      <td>home rafale aircraft rafale fighter jet india ...</td>\n",
              "      <td>[GenAI]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.geeksforgeeks.org/implementing-the...</td>\n",
              "      <td>Implementing the AdaBoost Algorithm From Scrat...</td>\n",
              "      <td>implement adaboost algorithm scratch last upda...</td>\n",
              "      <td>[ML, GenAI]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7552117d-1ddc-494b-b664-eb3e0fb263b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7552117d-1ddc-494b-b664-eb3e0fb263b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7552117d-1ddc-494b-b664-eb3e0fb263b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-206e1445-2974-4a43-a803-930ca2bb513b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-206e1445-2974-4a43-a803-930ca2bb513b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-206e1445-2974-4a43-a803-930ca2bb513b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"(cat_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"https://medium.com/analytics-vidhya/what-is-rnn-a157d903a88\",\n          \"https://www.geeksforgeeks.org/implementing-the-adaboost-algorithm-from-scratch/\",\n          \"https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Recurrent Neural Networks \\u2014 Complete and In-depth | by Tejas T A | Analytics Vidhya | Medium\",\n          \"Implementing the AdaBoost Algorithm From Scratch | GeeksforGeeks\",\n          \"What is a Transformer?. An Introduction to Transformers and\\u2026 | by Maxime | Inside Machine learning | Medium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"recurrent neural network complete tejas follow min read dec listen share rnn recurrent neural network type deep learning neural net remember input sequence store memory state predict future abstract study explore effectiveness recurrent neural network rnns predict customer behavior compare performance traditional machine learning model increase availability temporal data environment present unique opportunity improve customer behavior prediction leverage model capable capture sequential dependency use instacart market basket analysis dataset contain record customer purchase time case study evaluate prediction accuracy model like simple rnn long memory lstm gate recurrent unit gru traditional model logistic regression random forest serve benchmark comparison result indicate model outperform traditional model especially capture complex temporal pattern customer behavior use key evaluation metric accuracy precision recall demonstrate rnns provide robust framework understand predict customer action finding practical implication business look optimize marketing strategy personalize customer experience predict purchase pattern effectively future work may explore improvement integrate attention mechanism transformer model enhance predictive performance introduction background significance research today rapidly evolve landscape ability predict customer behavior become critical asset business company anticipate purchasing preference action customer well position personalize recommendation optimize inventory management design effective marketing strategy traditional machine learning model logistic regression decision tree widely use customer behavior prediction however model often struggle capture temporal dynamic inherent customer interaction lead suboptimal prediction scenario sequential data play key role rise deep learning particularly recurrent neural network rnns grow interest leverage model address limitation traditional approach rnns advanced variant long memory lstm gate recurrent unit gru design process sequential data make capture temporal dependency customer purchase pattern research explore application rnns predict customer behavior compare performance traditional machine learning model highlight advantage model statement problem despite potential rnns capture sequential pattern customer behavior remain limited empirical evidence compare performance traditional model application primary research problem study address determine whether rnns significantly outperform traditional machine learning model predict customer behavior particularly scenario involve sequential purchase data additionally study aim identify specific benefit limitation use rnns traditional method hypothesis hypothesize recurrent neural network rnns due ability model temporal dependency outperform traditional machine learning model predict customer behavior specifically model like lstm gru expect show high accuracy precision overall predictive performance apply customer purchase data objective study objective study follow evaluate effectiveness rnn model simple rnn lstm gru predict customer behavior use instacart market basket analysis dataset compare predictive performance rnns traditional machine learning model logistic regression random forest etc dataset analyze advantage rnns capture sequential pattern customer data implication business strategy identify potential limitation rnn model explore avenue improve prediction accuracy incorporation attention mechanism transformer model literature review overview exist research customer behavior prediction customer behavior prediction central focus field retail analytics decade traditional model primarily rely static feature customer demographic purchase history product attribute predict future action study researcher like verbeke et al neslin et al demonstrate effectiveness method variety business application include customer churn prediction product recommendation however increase temporal data availability new approach emerge model sequential customer behavior effectively recent research emphasize importance capture nature customer interaction study like fader hardie introduce model incorporate recency frequency monetary value rfm account temporal factor customer transaction however model often rely handcrafted feature limit inability capture complex sequential dependency time open door advanced technique include base deep learning discussion traditional machine learning model limitation traditional machine learn model logistic regression decision tree random forest method customer behavior prediction model highly interpretable widely use various industry due ability model categorical continuous variable efficiently example harford et al demonstrate effectiveness decision model predict customer churn response marketing campaign however despite utility traditional model face significant limitation come handle sequential data model operate assumption customer interaction independent ignore temporal dependency often crucial accurate prediction customer behavior prediction past event order product purchase direct impact future behavior limitation prompt researcher explore advanced approach account data moreover traditional model typically require manual feature engineering domain expert must define feature capture temporal pattern approach effective may fail capture complex relationship present data consequently researcher turn deep learning model capable learn temporal dependency directly data without need extensive feature engineering introduction rnns advantage handle temporal dependency recurrent neural network rnns design address shortcoming traditional machine learning model handle sequential data introduce rumelhart et al rnns allow information persist across time step make ideal task order event crucial customer behavior prediction mean rnns model progression customer purchase interaction preference time essential accurately forecasting future action advanced variant rnns long memory lstm network hochreiter schmidhuber gate recurrent unit gru cho et develop address vanishing gradient problem standard rnns face model allow capture dependency data make particularly effective situation event distant past influence present action customer purchase decision influence purchase make several month ago several study explore application rnns customer behavior prediction example zhang et al demonstrate lstm network outperform traditional model predict customer churn leverage sequential nature customer interaction similarly liu et al show gru model able effectively model purchase sequence lead improve product recommendation accuracy finding underscore potential rnns capture temporal pattern traditional model often miss neslin et verbeke et leverage sequential nature customer data rnns able predict future behavior accurately also provide deep insight dynamic customer interaction make valuable tool business seek personalize customer experience optimize marketing strategy predict future behavior base past action methodology description dataset dataset use study instacart market basket analysis dataset contain rich set transactional data popular grocery delivery service include information million online grocery order customer customer place multiple order allow dataset capture sequential purchasing behavior time dataset consist several table join use common set key order contains detail order include order id customer id order sequence first order second order etc day week hour day order place product include information product id product name category order product table link order product contain provide quantity product purchase give order customer information relate customer user id aisle department product classification broad category dataset allow construction sequence customer purchase time make highly suitable evaluate temporal model like recurrent neural network rnns provide insight customer behavior pattern product preference timing order essential behavior prediction data preprocessing step feed data predictive model several preprocessing step require convert raw dataset form use rnns traditional machine learning model primary step include step merging data table explanation instacart dataset spread across multiple table order product need merge table create unified dataset contain relevant information customer order product purchase merge dataset allow u create sequence purchase customer crucial feed model code import panda pd load datasets order product merge order get product detail order merge order merge product get name category product merge merge product display merged dataset print explanation use function join table use common key like result dataset contain column like use create sequential data step create sequence explanation rnns require sequential data input customer need group order arrange chronological order create sequence product purchase sequence represent list product buy several order serve input model code create sequence product purchase customer list display first sequence print explanation use groupby group dataset customer use apply list create list product customer base order history result sequence product id customer form input rnn step padding sequence explanation rnn model expect input sequence length however customer place number order ensure uniformity pad sequence fixed length sequence short length pad zero long sequence truncate code import set maximum length sequence order pad sequence length display padded sequence print explanation function pad sequence specify maximum length maxlen sequence short maximum length pad zero pad post argument ensure pad apply end sequence step ensure sequence equal length necessary train rnn model step split data explanation evaluate model performance need split dataset training validation test set training set use fit model validation set help hyperparameters test set use assess model performance unseen data code import split dataset training test set split training set training validation set display shape datasets print set size print set size print set size explanation use first split dataset training test set split training set training validation set test size set total dataset validation set training data ensure separate datasets model training tuning final evaluation step scale data need explanation dataset contain numerical feature like time day order frequency feature may need scale uniform range step ensure feature large range disproportionately affect model learn process code import minmaxscaler extract scale feature order scaler minmaxscaler display scaled time feature print explanation minmaxscaler use scale feature step ensure feature large value dominate learning process help improve model performance detailed explanation rnn architecture rnn explanation simple rnn basic form recurrent neural network simple rnn information pass hidden state one time step next hidden state time step depend input step also hidden state previous time step enable network retain memory previous input allow model sequential data architecture simple rnn describe follow time step input xt process along hidden state previous time step hidden state ht update use activation function like tanh relu output generate base update hidden state however simple rnns suffer vanish gradient problem make difficult retain information long sequence rumelhart hinton williams mainly use short sequence dependency critical rnn architecture diagram imagine looping structure time step receive input output hidden state hidden state pass forward next step sequence illustration simple rnn architecture input xt hide state pass one step next output time step base hidden state import sequential import simplernn dense define simple rnn model model sequential simplernn dense output layer compile model display model summary explanation code create simple rnn hidden unit input shape sequence length number feature output layer single neuron sigmoid activation function commonly use binary classification memory lstm explanation long memory lstm network advanced type rnn design overcome vanishing gradient problem simple rnns lstms capable learn dependency use special architecture include three gate input gate forget gate output gate gate control flow information network allow model retain discard information necessary hochreiter schmidhuber architecture lstm describe follow input gate determines information input add cell state forget gate decides information previous cell state discard output gate determines part cell state output hidden state gate mechanism allow lstms capture dependency make effective task speech recognition text generation forecasting lstm architecture diagram contrast simple rnn lstm unit contain memory cell ct addition hidden state three gate manage information flow within cell simplified diagram input xt cell state preserve memory hidden state pass one step next import lstm import lstm dense import adam define lstm model model sequential lstm dense compile model display model summary explanation example build lstm model hidden unit input shape still since lstm also expect sequential data lstm network powerful simple rnns task involve long sequence data gated recurrent unit gru explanation gated recurrent unit gru simplified version lstm combine forget input gate single update gate reduce complexity model retain many benefit lstms ability capture dependency grus tend perform similarly lstms computationally faster due simpler structure cho et architecture gru describe follow update gate determine much past information need pass future reset gate determine much past information forget hidden state update base gate allow gru capture dependency gru architecture diagram like lstms grus manage flow information gating mechanism however few gate separate cell state rely solely hidden state diagram overview input xt hide state update base update reset gate import gru define gru model model sequential gru dense compile model display model summary explanation define gru model hidden unit input shape grus often prefer computational efficiency concern faster lstms may perform similarly many task summary rnn architecture simple rnn work short sequence struggle dependency due vanish gradient problem lstm advanced architecture memory cell gate handle dependency make highly effective sequential data gru simplified version lstm few gate offer fast computation maintain performance long sequence architecture suit different task depend complexity data length sequence training procedure explanation training rnns include backpropagation time train recurrent neural network rnn include advanced architecture like lstm gru follow procedure somewhat similar traditional neural network main difference error propagate time process call backpropagation time bptt allow rnns learn sequential data let break key aspect training procedure pas forward pas input sequence process step step rnn time step model take input hidden state previous time step process generate output yt updated hidden state rnn represent w u weight matrix input hidden state respectively f activation function tanh relu b bias term hidden state previous time step current input time forward pas continue every time step sequence final output yt produce loss calculation end forward pas model calculate loss use appropriate loss function binary classification task mean squared error regression task loss measure far predict output yt actual target yt true sequence length total loss l calculate sum individual loss time step backpropagation time bptt traditional neural network error propagate backward layer update weight rnns process extend time call backpropagation time bptt work step error propagation error propagate backward time step loss final time step first propagate update weight last time step error previous time step use adjust hidden state weight early time step step weight update gradient loss respect weight compute time step weight matrix w input u hide state update require apply chain rule calculus propagate error across layer network across time well gradient key challenge bptt vanish gradient problem gradient shrink propagate backward make hard learn dependency lstms grus design mitigate problem use gate regulate flow information gradient bptt process time step compute loss propagate gradient backward hidden state update weight time step b move back time step propagate gradient update weight base loss time step c continue process time step process update weight matrix use gradient step optimizer gradient descent calculate gradient backpropagation optimizer use update model parameter weight bias commonly used optimizers training rnns adam stochastic gradient descent sgd adam optimizer optimizer adjust learning rate parameter base history gradient make effective complex architecture like rnns stochastic gradient descent sgd case sgd use especially simpler architecture model train small learning rate however adam generally prefer rnns due adaptive nature optimizer update weight w u bias b accord learning rate calculated gradient gradient descent update rule \\u03b7 learn rate gradient loss function respect weight training batch improve efficiency rnns usually train batch rather process one sequence time mean multiple sequence process parallel average loss across batch use update model weight training batch help stabilize gradient update make training process faster epochs epoch refers one complete pas entire training dataset training process typically run multiple epoch ensure model learn effectively epoch model performance evaluate validation set check overfitting underfitting lstm show train model use batch multiple epochs history evaluate model test set print loss test accuracy evaluation metric accuracy precision recall evaluation metric play crucial role assess well rnn model perform especially deal classification task detailed explanation metric accuracy definition accuracy straightforward evaluation metric measure proportion correctly classify instance positive negative total number tp true positive correctly predict positive instance tn true negative correctly predict negative instance fp false positive incorrectly predict positive instance fn false negative incorrectly predict negative instance explanation accuracy useful class balance mislead case imbalanced datasets example data negative model predict instance negative accuracy might still even though model completely fail predict positive class code calculate accuracy use keras metric model compilation accuracy also calculate automatically use print accuracy precision definition precision measure many predicted positive instance actually positive focus quality positive prediction make model explanation precision especially important cost false positive high instance spam detection precision crucial false positive mark legitimate email spam cause significant inconvenience code import predict class label test set calculate precision precision print precision recall sensitivity true positive rate definition recall measure many actual positive instance correctly predict model focus ability model identify positive instance explanation recall crucial miss positive instance costly example medical diagnosis low recall could mean miss detect disease patient could severe consequence code import calculate recall recall print recall definition harmonic mean precision recall provide single metric balance precision recall make useful need find balance explanation particularly helpful class distribution imbalanced give balanced view well model performs false positive false negative high mean model high precision high recall make good metric many classification problem code import calculate print receiver operating characteristic area curve definition roc curve graphical representation plot true positive rate recall false positive rate various threshold level auc area curve measure entire area underneath roc curve commonly use metric evaluate performance binary classifier true positive rate tpr recall calculate false positive rate fpr calculate explanation roc curve show well model distinguish class decision threshold change auc score range score indicates perfect classification score indicates model good random guessing auc model discrimination capacity distinguish positive negative class auc model perfectly distinguish positive negative class auc particularly useful imbalanced datasets accuracy might reflect model true performance code import predict class probability test set calculate score print visualize roc curve import plt import generate roc curve data fpr tpr threshold plot roc curve fpr tpr lstm positive rate positive rate curve result presentation experimental result presentation experimental result involve showcasing performance rnn model simple rnn lstm gru well traditional machine learning model customer behavior prediction task section highlight key comparison term accuracy precision recall alongside visualization provide intuitive understanding model performance setup evaluate following model instacart market basket analysis dataset traditional machine learning model logistic regression random forest recurrent neural network rnn model simple rnn lstm gru dataset split training validation test set model train use feature evaluate use test set ensure fair comparison metric comparison table table summarize key evaluation metric model key insight lstm model outperform traditional model rnn architecture across evaluation metric high accuracy gru performs similarly lstm slightly less accurate accuracy traditional machine learn like random forest logistic regression show lower overall performance particularly recall indicate limitation capture sequential dependency simple rnn show competitive performance fail match performance lstm gru due limitation handle dependency visualize model performance roc curve roc curve model provide visual comparison ability distinguish positive negative class across different threshold see chart lstm high area curve indicate superior performance curve curve demonstrate precision recall lstm show best balance make effective model task confusion matrix confusion matrix model highlight model make mistake particularly term false positive false negative lstm gru demonstrate few misclassifications compare traditional model simple rnn visualizing loss accuracy epochs training validation accuracy lstm gru show consistent improvement accuracy epoch indicate model learn effectively without overfitting simple rnn show slow convergence compare lstm gru training validation loss lstm low loss training validation indicate model generalize well gru also show low loss slightly high compare lstm whereas simple rnn show high loss value suggest struggle long sequence interpretation result result indicate model particularly lstm gru effective capture sequential nature customer purchase data lead good prediction customer behavior traditional model like logistic regression random forest unable model temporal dependency effectively lead lower performance metric lstm stand best performing model likely due ability capture dependency use memory cell make powerful tool type data recommendation base result base experimental result recommend lstm primary model business look predict customer behavior temporal data superior performance across metric make ideal application require high predictive accuracy gru alternative case computational efficiency important perform nearly well lstm few parameter faster training time traditional model like random forest consider simpler task temporal relationship crucial discussion analysis rnns perform well recurrent neural network rnns particularly advanced variant like lstm gru demonstrate superior performance traditional model logistic regression random forest customer behavior prediction several key factor explain rnns outperform traditional model capture temporal dependency rnns design process sequential data make ideal task like customer behavior prediction order past purchase play crucial role predict future action traditional model lack ability capture temporal dependency essential understand customer purchase pattern time memory lstms grus lstm gru architecture allow model retain information early time step effectively capture relationship especially valuable predict customer behavior past purchasing habit seasonal recur purchase influence future decision traditional model treat instance independent fail incorporate dependency dynamic complex data rnns excel learn dynamic sequential data pattern customer purchasing data inherently complex individual behavior change time contrast traditional model struggle relationship less effective handle evolve nature customer behavior feature engineering traditional model often rely extensive feature engineering capture sequential pattern contrast rnns especially lstms grus learn relevant feature directly data reduce need manual feature engineering discussion limitation potential improvement despite strong performance rnns lstms grus limitation could impact effectiveness certain context training complexity training model computationally intensive particularly large datasets rnns especially lstms grus high training complexity compare traditional model due backpropagation time bptt algorithm lead longer train time case may require computational resource gradient although lstms grus design mitigate vanishing gradient problem still affect model particularly process long sequence could limit ability rnns retain dependency effectively data requirement rnn model require substantial amount sequential data generalize well data sparse noisy performance may degrade traditional model may perform good situation limited data sequential dependency weak potential overfitting rnn model due complexity may prone overfitting particularly train small datasets regularization technique like dropout employ mitigate risk remain challenge potential improvement attention mechanism incorporate attention mechanism could improve performance rnns allow model focus specific part sequence relevant prediction would enhance ability capture dependency effectively transformer model transformer show outperform rnns many sequential task due parallelizable architecture mechanism future work incorporate transformer customer behavior prediction could improve accuracy training efficiency data augmentation improving data quality data augmentation technique create synthetic sequence could enhance performance rnn model especially available dataset limit implication business customer behavior prediction accurately predict customer behavior significantly impact business especially retail service result study suggest rnn model especially lstms grus provide significant business advantage term customer behavior analysis personalized marketing predict customer preference purchase behavior business deliver personalized marketing campaign could increase customer engagement lead high conversion rate example business offer targeted discount recommend product base predicted future purchase improve customer satisfaction loyalty inventory management accurate customer behavior prediction enable business optimize inventory management anticipate customer demand business better manage stock level reduce overstock stockouts optimize supply chain operation customer retention rnn model help identify customer likely churn leave service analyze past interaction behavior business use information implement retention strategy offer personalized incentive customer revenue optimization leverage prediction rnn model business optimize pricing strategy product recommendation could lead increase average order value high revenue per customer improved profitability improve use model effectively capture customer behavior business make decision help develop precise marketing strategy enhance product offering improve customer service conclusion application rnn model particularly lstm gru architecture represent powerful tool business aim predict influence customer behavior address limitation leverage future advancement like attention mechanism business enhance ability understand respond customer need conclusion summary key finding study explore effectiveness various machine learning model particularly recurrent neural network rnns predict customer behavior use instacart market basket analysis dataset key finding follow model especially lstm gru outperform traditional model logistic regression random forest predict customer behavior ability capture temporal dependency handle memory learn sequential data make well suit task lstm emerge model demonstrate high accuracy precision recall score architecture include memory cell gate mechanism allow retain utilize information customer purchase sequence effectively gru show similar performance lstm though slightly low accuracy slightly faster training process make good alternative computational efficiency priority traditional model useful certain task struggle handle sequential nature data result low accuracy recall fail capture intricate pattern customer purchasing behavior time simple rnns although capable handle sequential data less effective lstm gru due limitation vanish gradient problem reduced ability capture dependency suggestion future work finding study underscore power rnn model predict customer behavior several area improvement future exploration identify incorporating attention mechanism one key limitation rnns even advanced form lstm gru reliance processing sequence step step dilute importance critical time step integrate attention mechanism model focus relevant part sequence potentially improve performance attention allow model weigh different part input sequence differently give high importance critical input prediction task explore transformer model transformer architecture revolutionize natural language processing could offer significant improvement customer behavior prediction transformer highly parallelizable capture dependency sequence efficiently rnns test transformer customer behavior prediction task could reveal new opportunity enhance predictive accuracy reduce train time hybrid model future work could explore combine strength traditional machine learning model approach example hybrid model could use traditional method initial feature extraction rnns sequence modeling leverage strength approach prediction enhance model make prediction customer behavior personalized product recommendation live session could unlock significant value business would require improvement model efficiency deployment strategy potential impact customer satisfaction engagement would substantial transfer learn customer behavior applying transfer learn technique model train large customer datasets specific business industry could improve generalizability applicability model broad range use case data augmentation handle miss data case customer behavior data sparse incomplete employ data augmentation technique advanced method handle miss data could improve model performance robustness incorporate external data enrich customer behavior prediction model incorporate external data source economic indicator seasonal trend social medium activity could provide comprehensive insight improve predictive power model summary rnns especially lstm gru demonstrate strong predictive capability numerous avenue enhance performance applicability future integrate technique like attention mechanism transformer model business improve ability predict influence customer behavior drive good outcome marketing sale customer retention reference lecun bengio hinton deep learning nature vol pp may graf mohamed hinton speech recognition deep recurrent neural network proc ieee int conf speech signal process icassp vancouver bc canada may pp bahdanau cho bengio neural machine translation jointly learn align translate proc int conf learn representation iclr san diego ca usa may sutskever vinyals le sequence sequence learn neural network proc int conf neural inf process syst nip montreal qc canada pp hochreiter schmidhuber long memory neural computation vol pp glorot bordes bengio deep sparse rectifier neural network proc int conf artif intell stat aistats fort lauderdale fl usa apr pp cho et learn phrase representation use rnn statistical machine translation proc conf empirical method natural language process emnlp doha qatar pp chung gulcehre cho bengio empirical evaluation gated recurrent neural network sequence modeling proc nip workshop deep learning montreal qc canada mikolov karafi\\u00e1t burget cernock\\u00fd khudanpur recurrent neural network base language model proc annu conf int speech commun assoc interspeech makuhari japan pp mnih hinton scalable hierarchical distribute language model proc nip vancouver bc canada pp schuster paliwal bidirectional recurrent neural network ieee trans signal process vol pp hinton osindero teh fast learning algorithm deep belief net neural comput vol pp july krizhevsky sutskever hinton imagenet classification deep convolutional neural network proc nip lake tahoe nv usa pp glorot bengio understand difficulty train deep feedforward neural network proc int conf artif intell stat aistats sardinia italy may pp kim convolutional neural network sentence classification proc emnlp doha qatar pp goodfellow et generative adversarial net proc nip montreal qc canada pp collobert weston bottou karlen kavukcuoglu kuksa natural language processing almost scratch mach learn re vol pp\",\n          \"implement adaboost algorithm scratch last updated apr comment improve suggest change like article like report adaboost mean adaptive boosting powerful ensemble learning technique combine multiple weak classifier create strong classifier work sequentially add classifier correct error make previous model give weight misclassified data point article learn implement adaboost algorithm scratch make scratch deep understanding adaboost work key principle behind boost algorithms python implementation adaboost python provide special package apply adaboost see use python apply adaboost machine learning problem problem create synthetic dataset check implement import library let begin import important library require classification task python import numpy np import decisiontreeclassifier import import import import define adaboost class python class adaboost def self self self alphas self model adaboost class initialize number weak learner store weight model base performance store weak classifier decision stump use adaboost train adaboost model fit method python def fit self x x shape w np one retrieve number sample feature dataset w initializes sample weight uniformly python range self model decisiontreeclassifier model fit x w prediction model predict x err np sum w prediction np sum w alpha np log err err self alpha append alpha self model append model w w np exp alpha prediction w w np sum w err compute weighted error penalize misclassified sample alpha calculate model weight base error model low error receive high weight alpha alpha append model weight list model append trained weak classifier list w update sample weight base whether correctly incorrectly classified make prediction python def predict self x np zero x shape model alpha zip self model self alpha alpha model predict x return np sign astype int store aggregated prediction weak classifier example usage python x x adaboost adaboost adaboost fit prediction adaboost predict accuracy prediction precision prediction recall prediction prediction try prediction except valueerror require probability score print result print f accuracy accuracy print f precision precision print f recall recall print f score print f output accuracy precision recall score model performs well accuracy mean make correct prediction time good balance precision show make accurate positive prediction recall mean catch actual positive case score combine two measure show model good job tell difference two class overall metric indicate strong performance comment info advertise u next article xgboost follow improve article tag machine learn python python practice tag machine learning python\",\n          \"transformer maxime follow min read jan listen share introduction transformer learning machine learn new deep learning model introduce increase rate sometimes hard keep track novelty say one particular neural network model prove especially effective common natural language processing task model call transformer make use several method mechanism introduce paper refer post offer detailed quantitative description part sequence sequence learning attention paper attention need describes transformer call architecture neural net transform give sequence element sequence word sentence another sequence well might surprise consider name model particularly good translation sequence word one language transform sequence different word another language popular choice type model lstm model data lstm module give meaning sequence remember forget part find important unimportant sentence example since order word crucial understand sentence lstm natural choice type data model consist encoder decoder encoder take input sequence map high dimensional space vector abstract vector feed decoder turn output sequence output sequence another language symbol copy input etc imagine encoder decoder human translator speak two language first language mother tongue differ german french second language imaginary one common translate german french encoder convert german sentence language know namely imaginary language since decoder able read imaginary language translate language french together model consist encoder decoder translate german french suppose initially neither encoder decoder fluent imaginary language learn train model lot example basic choice encoder decoder model single lstm wondering transformer finally come play need one technical detail make transformer easy understand attention look input sequence decides step part sequence important sound abstract let clarify easy example read text always focus word read time mind still hold important keywords text memory order provide context work similarly give sequence example human encoder decoder imagine instead write translation sentence imaginary language encoder also write keywords important semantics sentence give decoder addition regular translation new keywords make translation much easy decoder know part sentence important key term give sentence context word input lstm encoder read take account several input time decides one important attribute different weight input decoder take input encoded sentence weight provide learn attention see article scientific approach one provide read different approach model great paper call effective approach neural machine translation part transformer paper attention need introduces novel architecture call transformer title indicate use saw earlier like lstm transformer architecture transform one sequence another one help two part encoder decoder differ previously model imply recurrent network gru lstm recurrent network one best way capture timely dependency sequence however team present paper prove architecture without rnn recurrent neural network improve result translation task task one improvement natural language task present team introduce bert bert deep bidirectional transformer language understanding exactly transformer image worth thousand word start figure attention need vaswani et al encoder left decoder right encoder decoder compose module stack top multiple time describe nx figure see module consist mainly attention fee forward layer input output target sentence first embed space since use string directly one slight important part model positional encoding different word since recurrent network remember sequence feed model need somehow give every sequence relative position since sequence depend order element position add embed representation vector word let close look attention brick model figure attention need vaswani et al let start left description complicate describe following equation q matrix contain query vector representation one word sequence k key vector representation word sequence v value vector representation word sequence encoder decoder attention module v consists word sequence however attention module take account encoder decoder sequence v different sequence represent simplify little bit could say value v multiply sum weight define mean weight define word sequence represent q influence word sequence represent k additionally softmax function apply weight distribution weight apply word sequence introduce v vector q encoder decoder different module encoder decoder input righthand picture describe parallelize multiple mechanism use side side attention mechanism repeat multiple time linear projection q k allow system learn different representation q k v beneficial model linear representation do multiply q k v weight matrix w learn training matrix q k v different position attention module structure depend whether encoder decoder encoder decoder reason want attend either whole encoder input sequence part decoder input sequence attention module connect encoder decoder make sure encoder take account together decoder give position head encoder decoder pointwise layer little network identical parameter position describe separate identical linear transformation element give sequence train train beast training infer model bit different usual classification problem true transformer know train model translation task need two sentence different language translation lot sentence pair start train model let say want translate french german encoded input french sentence input decoder german sentence however decoder input shift right one position wait one reason want model learn copy decoder input training want learn give encoder sequence particular decoder sequence already see model predict next shift decoder sequence model learn simply copy decoder input since target position would decoder input thus shift decoder input one position model need predict target position see decoder sequence prevent model learn task fill first position decoder input token since place would otherwise empty similarly append token decoder input sequence mark end sequence also append target output sentence moment see useful infer result true model transformer addition transformer apply mask input first attention module avoid see potential future sequence element specific transformer architecture rnns input sequence sequentially input everything together mask attention would consider whole decoder input sequence position process feed correct shift input decoder also call describe blog target sequence want loss calculation simply decoder input german sentence without shift token end inference infer model different training make sense end want translate french sentence without german sentence trick model position output sequence come across token step step method would input full encoder sequence french sentence decoder input take empty sequence token first position output sequence take first element element fill second position decoder input sequence token first input encoder sequence new decoder sequence model take second element output put decoder input sequence repeat predict token mark end translation see need multiple run model translate sentence hope description make transformer architecture little bit clearer everybody start structure part transformer see transformer architecture know literature attention need author model extremely well language task let test transformer use case instead translation task let implement forecast hourly flow electrical power texas provide electric reliability council texas ercot find hourly data great detailed explanation transformer implementation provide harvardnlp want dig deeper architecture recommend go implementation since use model make forecast prediction let look transformer power make prediction however first need make change architecture since work sequence word value additionally classification data available data give u hourly load entire ercot control area use data year training set year test set load value timestamp load expand timestamp feature timestamp extract weekday correspond encode additionally use year corresponding hour value give feature total hour day convergence purpose also normalize ercot load divide predict give sequence need sequence past size window vary example use hourly data previous hour predict next hour help adjust size window depend need example change daily data instead hourly data change model paper first step need remove embeddings since already numerical value input embed usually map give integer space instead use embedding simply use linear transformation transform data space similar embed word also need remove softmax layer output transformer output node probability real value minor change training begin mentioned use teacher force training mean encoder get window data point input decoder input window data point first one value following data point simply target sequence introduce value beginning shift decoder input one position regard target sequence use vector value course change perhaps would beneficial use value depend use case example work since never negative value either dimension sequence loss function example simply mean square error result two plot show result take mean value hourly value per day compare correct value first plot show prediction give previous hour second plot predict one hour give previous hour see model able catch fluctuation well root mean square error training set validation set prediction prediction correspond mean absolute percentage error model prediction first plot second one figure prediction give previous hour one year figure prediction give previous hour one year summary result show would possible use transformer architecture forecast however evaluation show step want forecast high error become first graph figure achieve use hour predict next hour predict one hour result much good see second graph figure plenty room play around parameter transformer number decoder encoder layer etc intend perfect model good tuning training result would probably improve big help accelerate training use gpus use watson studio local platform train model gpus let run rather local machine also accelerate training use watson machine learn gpus free certain amount training time check previous blog see integrate easily code thank much read hope able clarify notion people start get deep learning\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "Gemini_api_key=userdata.get('Gemini_api_key')\n",
        "\n",
        "import google.generativeai as genai\n",
        "#generating abstractive summary using gemini as the system's motive is to assist students\n",
        "# so keeping it in more human readable format\n",
        "\n",
        "genai.configure(api_key=Gemini_api_key)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "\n",
        "summaries = []\n",
        "\n",
        "for index, row in cat_df.iterrows():\n",
        "    try:\n",
        "        text = row[\"cleaned_text\"][:15000]\n",
        "        source = row[\"source\"]\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Summarize the following article in two ways:\n",
        "\n",
        "        1. A **brief summary** in 2–3 lines.\n",
        "        2. A **detailed summary** in 5–7 lines.\n",
        "\n",
        "        Article:\n",
        "        {text}\n",
        "        \"\"\"\n",
        "        response = model.generate_content(prompt)\n",
        "        output = response.text.strip()\n",
        "\n",
        "        summaries.append({\n",
        "            \"source\": source,\n",
        "            \"summary\": output\n",
        "        })\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        summaries.append({\n",
        "            \"source\": row[\"source\"],\n",
        "            \"summary\": f\"Error: {str(e)}\"\n",
        "        })\n",
        "\n",
        "# Convert to DataFrame and save\n",
        "summary_df = pd.DataFrame(summaries)\n",
        "\n",
        "summary_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jcpb45kdnUj-",
        "outputId": "099dd7c5-95ac-461e-f247-4aee5ce8076d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              source  \\\n",
              "0  https://medium.com/@jh.baek.sd/chroma-vs-faiss...   \n",
              "1  https://medium.com/analytics-vidhya/what-is-rn...   \n",
              "2  https://medium.com/inside-machine-learning/wha...   \n",
              "3  https://vajiramandravi.com/upsc-exam/rafale-fi...   \n",
              "4  https://www.geeksforgeeks.org/implementing-the...   \n",
              "\n",
              "                                             summary  \n",
              "0  **Brief Summary (2-3 lines):**\\n\\nThis article...  \n",
              "1  **Brief Summary:**\\n\\nThis article explores us...  \n",
              "2  Error: ('Connection aborted.', RemoteDisconnec...  \n",
              "3  **Brief Summary:**\\n\\nThe Rafale is a versatil...  \n",
              "4  Error: ('Connection aborted.', RemoteDisconnec...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f308a2ce-424e-415d-8e55-82eafe22cedf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://medium.com/@jh.baek.sd/chroma-vs-faiss...</td>\n",
              "      <td>**Brief Summary (2-3 lines):**\\n\\nThis article...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://medium.com/analytics-vidhya/what-is-rn...</td>\n",
              "      <td>**Brief Summary:**\\n\\nThis article explores us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://medium.com/inside-machine-learning/wha...</td>\n",
              "      <td>Error: ('Connection aborted.', RemoteDisconnec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://vajiramandravi.com/upsc-exam/rafale-fi...</td>\n",
              "      <td>**Brief Summary:**\\n\\nThe Rafale is a versatil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.geeksforgeeks.org/implementing-the...</td>\n",
              "      <td>Error: ('Connection aborted.', RemoteDisconnec...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f308a2ce-424e-415d-8e55-82eafe22cedf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f308a2ce-424e-415d-8e55-82eafe22cedf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f308a2ce-424e-415d-8e55-82eafe22cedf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f5f160c2-66e6-441b-a32e-4fcd466bb7ef\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5f160c2-66e6-441b-a32e-4fcd466bb7ef')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f5f160c2-66e6-441b-a32e-4fcd466bb7ef button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary_df",
              "summary": "{\n  \"name\": \"summary_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"https://www.geeksforgeeks.org/box-cox-transformation-using-python/\",\n          \"https://www.ibm.com/think/topics/fine-tuning\",\n          \"https://medium.com/@jh.baek.sd/chroma-vs-faiss-a-comparative-analysis-527a4f3c8fb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"**Brief Summary:**\\n\\nEnsemble learning combines multiple machine learning models (learners) to achieve better predictive performance than any individual model could achieve alone.  It addresses issues like limited datasets, bias-variance tradeoff, and overfitting.  Popular techniques include bagging, boosting, and stacking.\\n\\n**Detailed Summary:**\\n\\nEnsemble learning aggregates predictions from multiple base learners (e.g., regression models, neural networks) to improve overall accuracy. This approach is particularly useful for addressing limitations with individual models trained on limited or complex datasets.  It leverages the principle of collectivity, where combined models outperform individual ones.  Different ensemble methods exist, categorized as parallel (bagging, stacking) or sequential (boosting), and can use homogeneous or heterogeneous base learners.  These methods effectively manage the bias-variance tradeoff and can improve model fairness and generalizability.  Research continues to explore ensemble learning for applications like computer vision and addressing algorithmic bias.\",\n          \"**Brief Summary:**\\n\\nThe Bernoulli distribution is a statistical tool used to calculate the probability of two possible outcomes (success or failure) in a single trial, like flipping a coin.  It involves key parameters like the probability of success (p) and failure (q). This distribution forms the basis for other distributions like the binomial and geometric.\\n\\n**Detailed Summary:**\\n\\nThe Bernoulli distribution models a single trial with two outcomes: success or failure, with constant probability of success (p).  The probability of failure (q) is the complement of p (q=1-p).  The mean of the distribution is equal to p, and the variance is p*q.  It's used in various applications like quality control, where a product either passes or fails, and market research, where a customer is either satisfied or dissatisfied.  While similar to the binomial distribution, the Bernoulli focuses on a single trial, whereas the binomial considers multiple trials.  It is also foundational to other distributions like the geometric and negative binomial.\",\n          \"**Brief Summary (2-3 lines):**\\n\\nThis article compares Chroma and FAISS, two tools for working with vector embeddings. Chroma is a user-friendly vector database designed for building AI applications, while FAISS is a highly efficient library specializing in similarity search and clustering.  The comparison focuses on their features and use cases.\\n\\n**Detailed Summary (5-7 lines):**\\n\\nThe article presents a comparative analysis of Chroma and FAISS for managing vector embeddings. Chroma, a vector database, prioritizes ease of use and seamless local development, making it suitable for prototyping AI applications with embedding-heavy workloads. In contrast, FAISS, a library developed by Facebook, excels in efficient similarity search and clustering of dense vectors. Key differences include Chroma's simplified setup and focus on application building, while FAISS offers greater control and efficiency as a standalone library for similarity search, benefiting from its open-source nature. The comparison aims to guide developers in choosing the right tool based on their specific needs.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = summary_df\n",
        "\n",
        "# Function to split summary into brief and detailed parts\n",
        "def split_summary(text):\n",
        "    # Check if there's a detailed summary section\n",
        "    if \"**Detailed Summary\" in text:\n",
        "        parts = text.split(\"**Detailed Summary\")\n",
        "        brief_summary = parts[0].replace(\"**Brief Summary (2-3 lines):**\", \"\").replace(\"**Brief Summary:**\", \"\").strip()\n",
        "        detailed_summary = parts[1].split(\":**\")[1].strip() if \":**\" in parts[1] else parts[1].strip()\n",
        "    else:\n",
        "        # If no detailed summary, put everything in brief summary\n",
        "        brief_summary = text.replace(\"**Brief Summary (2-3 lines):**\", \"\").replace(\"**Brief Summary:**\", \"\").strip()\n",
        "        detailed_summary = \"\"\n",
        "\n",
        "    return brief_summary, detailed_summary\n",
        "\n",
        "# Apply function to create new columns\n",
        "df[['Brief Summary', 'Detailed Summary']] = df['summary'].apply(lambda x: pd.Series(split_summary(x)))\n",
        "\n",
        "# Select only the columns we want in the final dataframe\n",
        "result_df = df[['source', 'Brief Summary', 'Detailed Summary']]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PtFovEWEwUm8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_json(\"split_gemini_summaries.json\", indent=2)"
      ],
      "metadata": {
        "id": "F5NMl5Ev1wMR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import json\n",
        "\n",
        "def chunk_document(text, chunk_size=500):\n",
        "    \"\"\"Splits text into fixed-size chunks.\"\"\"\n",
        "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "chunked_data = []\n",
        "\n",
        "for _, row in cat_df.iterrows():\n",
        "    chunks = chunk_document(row['cleaned_text'], chunk_size=500)\n",
        "    for chunk in chunks:\n",
        "        chunked_data.append({\n",
        "            \"title\": row['title'],\n",
        "            \"source\": row['source'],\n",
        "            \"category\": row['categories'],\n",
        "            \"text_chunk\": chunk\n",
        "        })\n",
        "\n",
        "\n",
        "with open(\"chunked_ai_articles.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(chunked_data, f, indent=2, ensure_ascii=False)\n"
      ],
      "metadata": {
        "id": "ub7EDiV46rUm"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# Configure API\n",
        "client = genai.Client(api_key=Gemini_api_key)\n",
        "\n",
        "# File paths\n",
        "INDEX_PATH = \"ai_articles_index.faiss\"\n",
        "METADATA_PATH = \"ai_articles_metadata.json\"\n",
        "\n",
        "# Load existing FAISS index + metadata\n",
        "def load_existing():\n",
        "    if os.path.exists(INDEX_PATH):\n",
        "        index = faiss.read_index(INDEX_PATH)\n",
        "        with open(METADATA_PATH, 'r') as f:\n",
        "            metadata = json.load(f)\n",
        "        print(f\"Loaded index with {index.ntotal} vectors.\")\n",
        "    else:\n",
        "        index = None\n",
        "        metadata = []\n",
        "        print(\"No existing index found.\")\n",
        "    return index, metadata\n",
        "\n",
        "# Save FAISS index + metadata\n",
        "def save_all(index, metadata):\n",
        "    faiss.write_index(index, INDEX_PATH)\n",
        "    with open(METADATA_PATH, 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "    print(f\"Saved index with {index.ntotal} vectors.\")\n",
        "\n",
        "# Retry logic for Gemini embedding\n",
        "def get_embedding(text, retries=5, delay=1):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            result = client.models.embed_content(\n",
        "                model=\"gemini-embedding-exp-03-07\",\n",
        "                contents=text,\n",
        "                config=types.EmbedContentConfig(task_type=\"RETRIEVAL_DOCUMENT\")\n",
        "            )\n",
        "            return result.embeddings[0].values\n",
        "        except Exception as e:\n",
        "            if \"429\" in str(e) or \"RESOURCE_EXHAUSTED\" in str(e):\n",
        "                wait = delay * (2 ** attempt) + random.uniform(0, 0.5)\n",
        "                print(f\"Rate limited. Waiting {wait:.1f}s...\")\n",
        "                time.sleep(wait)\n",
        "            else:\n",
        "                print(f\"Error: {e}\")\n",
        "                if attempt == retries - 1:\n",
        "                    raise e\n",
        "\n",
        "# Main embedding function\n",
        "def embed_chunks(chunks_json_path):\n",
        "    with open(chunks_json_path, 'r') as f:\n",
        "        chunks = json.load(f)\n",
        "    print(f\"Loaded {len(chunks)} text chunks.\")\n",
        "\n",
        "    index, metadata = load_existing()\n",
        "\n",
        "    # Track already processed by (source + first 30 chars of text)\n",
        "    processed_keys = {\n",
        "        (m[\"source\"], m[\"text_chunk\"][:30]) for m in metadata\n",
        "    }\n",
        "\n",
        "    new_embeddings = []\n",
        "    new_metadata = []\n",
        "    dim = None  # To store embedding dimension\n",
        "\n",
        "    for chunk in tqdm(chunks):\n",
        "        key = (chunk[\"source\"], chunk[\"text_chunk\"][:30])\n",
        "        if key in processed_keys:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            emb = get_embedding(chunk[\"text_chunk\"])\n",
        "\n",
        "            # Check if this is our first embedding or if dimensions match\n",
        "            if dim is None:\n",
        "                dim = len(emb)\n",
        "            elif len(emb) != dim:\n",
        "                print(f\"Warning: Embedding dimension mismatch. Expected {dim}, got {len(emb)}. Skipping chunk.\")\n",
        "                continue\n",
        "\n",
        "            new_embeddings.append(emb)\n",
        "            new_metadata.append({\n",
        "    \"source\": chunk[\"source\"],\n",
        "    \"title\": chunk.get(\"title\", \"\"),\n",
        "    \"text_chunk\": chunk[\"text_chunk\"]\n",
        "})\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to embed chunk: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Save to FAISS\n",
        "    if new_embeddings:\n",
        "        try:\n",
        "            # Ensure consistent dimensions before creating array\n",
        "            emb_array = np.array(new_embeddings, dtype=np.float32)\n",
        "\n",
        "            if index is None:\n",
        "                index = faiss.IndexFlatL2(emb_array.shape[1])\n",
        "\n",
        "            index.add(emb_array)\n",
        "            metadata.extend(new_metadata)\n",
        "            save_all(index, metadata)\n",
        "            print(f\"Added {len(new_embeddings)} new vectors.\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error creating embedding array: {e}\")\n",
        "            print(\"Trying to save individually...\")\n",
        "\n",
        "            # Alternative approach: Add vectors one by one\n",
        "            if index is None and dim:\n",
        "                index = faiss.IndexFlatL2(dim)\n",
        "\n",
        "            successful = 0\n",
        "            for i, emb in enumerate(new_embeddings):\n",
        "                try:\n",
        "                    single_vector = np.array([emb], dtype=np.float32)\n",
        "                    index.add(single_vector)\n",
        "                    metadata.append(new_metadata[i])\n",
        "                    successful += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to add vector {i}: {e}\")\n",
        "\n",
        "            if successful > 0:\n",
        "                save_all(index, metadata)\n",
        "                print(f\"Added {successful} vectors individually.\")\n",
        "    else:\n",
        "        print(\"No new embeddings added.\")\n",
        "\n",
        "# Call the embedding function\n",
        "if __name__ == \"__main__\":\n",
        "    embed_chunks(\"chunked_ai_articles.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrT6l73gZJ4a",
        "outputId": "dd6285c5-7b49-426f-bdba-3adf42e0099d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 300 text chunks.\n",
            "No existing index found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:27<02:13,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limited. Waiting 1.3s...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 51/300 [00:29<03:51,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limited. Waiting 1.2s...\n",
            "Rate limited. Waiting 2.1s...\n",
            "Rate limited. Waiting 4.2s...\n",
            "Rate limited. Waiting 8.3s...\n",
            "Rate limited. Waiting 16.1s...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 52/300 [01:01<42:32, 10.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to embed chunk: object of type 'NoneType' has no len()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 104/300 [01:29<01:44,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limited. Waiting 1.4s...\n",
            "Rate limited. Waiting 2.0s...\n",
            "Rate limited. Waiting 4.0s...\n",
            "Rate limited. Waiting 8.4s...\n",
            "Rate limited. Waiting 16.2s...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 105/300 [02:01<32:57, 10.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to embed chunk: object of type 'NoneType' has no len()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 155/300 [02:29<01:17,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limited. Waiting 1.0s...\n",
            "Rate limited. Waiting 2.2s...\n",
            "Rate limited. Waiting 4.4s...\n",
            "Rate limited. Waiting 8.5s...\n",
            "Rate limited. Waiting 16.5s...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 156/300 [03:02<24:33, 10.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to embed chunk: object of type 'NoneType' has no len()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▊   | 206/300 [03:29<00:50,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limited. Waiting 1.2s...\n",
            "Rate limited. Waiting 2.2s...\n",
            "Rate limited. Waiting 4.5s...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 207/300 [03:37<04:36,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limited. Waiting 1.2s...\n",
            "Rate limited. Waiting 2.4s...\n",
            "Rate limited. Waiting 4.4s...\n",
            "Rate limited. Waiting 8.4s...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 257/300 [04:21<00:22,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limited. Waiting 1.3s...\n",
            "Rate limited. Waiting 2.3s...\n",
            "Rate limited. Waiting 4.0s...\n",
            "Rate limited. Waiting 8.2s...\n",
            "Rate limited. Waiting 16.1s...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 258/300 [04:53<07:02, 10.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to embed chunk: object of type 'NoneType' has no len()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [05:16<00:00,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved index with 296 vectors.\n",
            "Added 296 new vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search_similar_excerpts(query, index, metadata, top_k=5):\n",
        "    \"\"\"\n",
        "    Search for similar excerpts using FAISS index.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query text to search for\n",
        "        index (faiss.Index): The FAISS index object\n",
        "        metadata (list): List of metadata dictionaries for each vector\n",
        "        top_k (int): Number of top results to return\n",
        "\n",
        "    Returns:\n",
        "        list: List of dictionaries containing text and source information\n",
        "    \"\"\"\n",
        "    # Embed the query\n",
        "    query_embedding = get_embedding(query, retries=2, delay=1)\n",
        "\n",
        "    # Need to convert the embedding to a numpy array with correct shape and type\n",
        "    query_array = np.array([query_embedding]).astype('float32')\n",
        "\n",
        "    # Search in FAISS\n",
        "    D, I = index.search(query_array, top_k)\n",
        "\n",
        "    # Return results\n",
        "    results = []\n",
        "    for i, idx in enumerate(I[0]):\n",
        "        if idx != -1 and idx < len(metadata):  # Check for valid index (-1 means no result found)\n",
        "            result = {\n",
        "                \"title\": metadata[idx].get('title', 'N/A'),\n",
        "                \"score\": float(D[0][i]),\n",
        "                \"source\": metadata[idx].get('source', 'N/A'),\n",
        "                \"text_chunk\": metadata[idx].get('text_chunk', metadata[idx].get('text', 'N/A'))\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Load existing index and metadata\n",
        "def load_index_and_search(query, top_k=5):\n",
        "    \"\"\"Helper function to load index and search in one step\"\"\"\n",
        "    import faiss\n",
        "    import json\n",
        "\n",
        "    # Load index and metadata\n",
        "    INDEX_PATH = \"ai_articles_index.faiss\"\n",
        "    METADATA_PATH = \"ai_articles_metadata.json\"\n",
        "\n",
        "    index = faiss.read_index(INDEX_PATH)\n",
        "    with open(METADATA_PATH, 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    # Perform search\n",
        "    return search_similar_excerpts(query, index, metadata, top_k)"
      ],
      "metadata": {
        "id": "S-chp1dokWX5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What do you understand by encoders and decoders?\"\n",
        "results = load_index_and_search(query, top_k=5)\n",
        "\n",
        "for i, r in enumerate(results, 1):\n",
        "    print(f\"{i} Title:{r['title']}\\n Source: {r['source']}\\n {r['text_chunk']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGHRMfsElJH0",
        "outputId": "04b5bf52-12ef-459b-c4d9-1eae2c74a52a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Title:What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            " Source: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            "  take input sequence map high dimensional space vector abstract vector feed decoder turn output sequence output sequence another language symbol copy input etc imagine encoder decoder human translator speak two language first language mother tongue differ german french second language imaginary one common translate german french encoder convert german sentence language know namely imaginary language since decoder able read imaginary language translate language french together model consist encod\n",
            "\n",
            "2 Title:💡 What is Prompt Engineering ?:: RAG, CoT, ReAct & DSP Explained | by Tahir | Medium\n",
            " Source: https://medium.com/@tahirbalarabe2/what-is-prompt-engineering-rag-cot-react-dsp-explained-0aa0a9bd0a90\n",
            " nstructured question\n",
            "\n",
            "3 Title:What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            " Source: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            " er decoder translate german french suppose initially neither encoder decoder fluent imaginary language learn train model lot example basic choice encoder decoder model single lstm wondering transformer finally come play need one technical detail make transformer easy understand attention look input sequence decides step part sequence important sound abstract let clarify easy example read text always focus word read time mind still hold important keywords text memory order provide context work si\n",
            "\n",
            "4 Title:What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            " Source: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            " y vector representation word sequence v value vector representation word sequence encoder decoder attention module v consists word sequence however attention module take account encoder decoder sequence v different sequence represent simplify little bit could say value v multiply sum weight define mean weight define word sequence represent q influence word sequence represent k additionally softmax function apply weight distribution weight apply word sequence introduce v vector q encoder decoder \n",
            "\n",
            "5 Title:What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            " Source: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            "  attention module connect encoder decoder make sure encoder take account together decoder give position head encoder decoder pointwise layer little network identical parameter position describe separate identical linear transformation element give sequence train train beast training infer model bit different usual classification problem true transformer know train model translation task need two sentence different language translation lot sentence pair start train model let say want translate fr\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "import random\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "def rerank_with_gemini(query: str, search_results: List[Dict[str, Any]],\n",
        "                       client = client, model_name=\"gemini-1.5-pro\",\n",
        "                       top_k=3, max_retries=3):\n",
        "    \"\"\"\n",
        "    Rerank search results using Gemini 1.5 Pro to improve relevancy.\n",
        "\n",
        "    Args:\n",
        "        query (str): The original user query\n",
        "        search_results (list): List of initial search results (from FAISS)\n",
        "        client: Gemini API client (if None, will use global client)\n",
        "        model_name (str): Gemini model to use\n",
        "        top_k (int): Number of results to return after reranking\n",
        "        max_retries (int): Maximum number of retries on API failure\n",
        "\n",
        "    Returns:\n",
        "        list: Reranked search results\n",
        "    \"\"\"\n",
        "    if not search_results:\n",
        "        return []\n",
        "\n",
        "\n",
        "\n",
        "    # Prepare content for Gemini\n",
        "    passages = []\n",
        "    for i, result in enumerate(search_results):\n",
        "        passages.append(f\"Passage {i+1}: {result['text_chunk']}\")\n",
        "\n",
        "    passages_text = \"\\n\\n\".join(passages)\n",
        "\n",
        "    # Create the prompt for Gemini\n",
        "    prompt = f\"\"\"\n",
        "    You are a search reranker. I'll provide a query and several passages.\n",
        "    Rerank the passages based on their relevance to the query.\n",
        "\n",
        "    Query: {query}\n",
        "\n",
        "    Passages:\n",
        "    {passages_text}\n",
        "\n",
        "    Instructions:\n",
        "    1. Analyze each passage for relevance to the query\n",
        "    2. Consider both semantic relevance and information value\n",
        "    3. Provide a JSON response with the reranked passages\n",
        "    4. Include a relevance score (1-10) and a brief explanation\n",
        "\n",
        "    Return only valid JSON in this format:\n",
        "    {{\n",
        "        \"reranked_results\": [\n",
        "            {{\n",
        "                \"passage_index\": [original passage number],\n",
        "                \"relevance_score\": [score between 1-10],\n",
        "                \"explanation\": [brief explanation of relevance]\n",
        "            }},\n",
        "            ...\n",
        "        ]\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    # Function to make API call with retry logic\n",
        "    def call_gemini_with_retry(attempts=0):\n",
        "        try:\n",
        "            response = client.models.generate_content(\n",
        "                model=model_name,\n",
        "                contents=prompt,\n",
        "                config=types.GenerateContentConfig(\n",
        "                temperature=0.1,\n",
        "                response_mime_type=\"application/json\",\n",
        "                max_output_tokens=2048\n",
        "            ),\n",
        "            )\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            if attempts < max_retries:\n",
        "                wait_time = 2 ** attempts + random.uniform(0, 1)\n",
        "                print(f\"API error: {e}. Retrying in {wait_time:.1f} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "                return call_gemini_with_retry(attempts + 1)\n",
        "            else:\n",
        "                print(f\"Failed after {max_retries} attempts: {e}\")\n",
        "                # Fall back to original order if reranking fails\n",
        "                return json.dumps({\n",
        "                    \"reranked_results\": [\n",
        "                        {\"passage_index\": i+1, \"relevance_score\": 5, \"explanation\": \"Default ranking\"}\n",
        "                        for i in range(len(search_results))\n",
        "                    ]\n",
        "                })\n",
        "\n",
        "    # Get reranking from Gemini\n",
        "    response_text = call_gemini_with_retry()\n",
        "\n",
        "    # Extract JSON from response (in case model outputs additional text)\n",
        "    json_match = re.search(r'({.*})', response_text.replace('\\n', ' '), re.DOTALL)\n",
        "    if json_match:\n",
        "        try:\n",
        "            reranking_data = json.loads(json_match.group(1))\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error parsing JSON from Gemini response\")\n",
        "            return search_results[:top_k]  # Return original order if parsing fails\n",
        "    else:\n",
        "        print(\"No JSON found in Gemini response\")\n",
        "        return search_results[:top_k]\n",
        "\n",
        "    # Process reranking results\n",
        "    reranked = []\n",
        "    try:\n",
        "        # Sort by relevance score in descending order\n",
        "        sorted_rankings = sorted(\n",
        "            reranking_data[\"reranked_results\"],\n",
        "            key=lambda x: x[\"relevance_score\"],\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        # Map back to original results\n",
        "        for ranking in sorted_rankings[:top_k]:\n",
        "            orig_idx = ranking[\"passage_index\"] - 1  # Convert back to 0-based index\n",
        "            if 0 <= orig_idx < len(search_results):\n",
        "                result = search_results[orig_idx].copy()\n",
        "                result[\"relevance_score\"] = ranking[\"relevance_score\"]\n",
        "                result[\"explanation\"] = ranking[\"explanation\"]\n",
        "                reranked.append(result)\n",
        "    except (KeyError, IndexError) as e:\n",
        "        print(f\"Error processing reranking results: {e}\")\n",
        "        return search_results[:top_k]  # Return original order if processing fails\n",
        "\n",
        "    return reranked\n",
        "\n",
        "# Example usage\n",
        "def search_and_rerank(query, top_k_initial=10, top_k_final=5):\n",
        "    \"\"\"\n",
        "    Perform vector search and rerank results using Gemini.\n",
        "\n",
        "    Args:\n",
        "        query (str): The user's query\n",
        "        top_k_initial (int): Number of initial results to get from FAISS\n",
        "        top_k_final (int): Number of results to return after reranking\n",
        "\n",
        "    Returns:\n",
        "        list: Reranked search results\n",
        "    \"\"\"\n",
        "    # First get initial results from FAISS (get more than we need for reranking)\n",
        "    initial_results = load_index_and_search(query, top_k=top_k_initial)\n",
        "\n",
        "    # Then rerank using Gemini\n",
        "    reranked_results = rerank_with_gemini(query, initial_results, top_k=top_k_final)\n",
        "\n",
        "    return reranked_results"
      ],
      "metadata": {
        "id": "ZI1Pu1AaqDGU"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What do you understand by encoders and decoders?\"\n",
        "results = search_and_rerank(query, top_k_initial=10, top_k_final=5)\n",
        "\n",
        "# now here the results are based on semantic meaning rather than simailarity scores\n",
        "for i, r in enumerate(results, 1):\n",
        "    print(f\"{i} Title:{r['title']}\\n Source: {r['source']}\\n {r['text_chunk']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm7cWxGFqId_",
        "outputId": "101dbb30-7f89-4ad3-f0b3-6132b6c78032"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Title:What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            " Source: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            " ll architecture neural net transform give sequence element sequence word sentence another sequence well might surprise consider name model particularly good translation sequence word one language transform sequence different word another language popular choice type model lstm model data lstm module give meaning sequence remember forget part find important unimportant sentence example since order word crucial understand sentence lstm natural choice type data model consist encoder decoder encoder\n",
            "\n",
            "2 Title:What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            " Source: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            "  paper prove architecture without rnn recurrent neural network improve result translation task task one improvement natural language task present team introduce bert bert deep bidirectional transformer language understanding exactly transformer image worth thousand word start figure attention need vaswani et al encoder left decoder right encoder decoder compose module stack top multiple time describe nx figure see module consist mainly attention fee forward layer input output target sentence fir\n",
            "\n",
            "3 Title:What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            " Source: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            "  take input sequence map high dimensional space vector abstract vector feed decoder turn output sequence output sequence another language symbol copy input etc imagine encoder decoder human translator speak two language first language mother tongue differ german french second language imaginary one common translate german french encoder convert german sentence language know namely imaginary language since decoder able read imaginary language translate language french together model consist encod\n",
            "\n",
            "4 Title:What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            " Source: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            " different module encoder decoder input righthand picture describe parallelize multiple mechanism use side side attention mechanism repeat multiple time linear projection q k allow system learn different representation q k v beneficial model linear representation do multiply q k v weight matrix w learn training matrix q k v different position attention module structure depend whether encoder decoder encoder decoder reason want attend either whole encoder input sequence part decoder input sequence\n",
            "\n",
            "5 Title:What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            " Source: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            " ench german encoded input french sentence input decoder german sentence however decoder input shift right one position wait one reason want model learn copy decoder input training want learn give encoder sequence particular decoder sequence already see model predict next shift decoder sequence model learn simply copy decoder input since target position would decoder input thus shift decoder input one position model need predict target position see decoder sequence prevent model learn task fill f\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " here the differences in results is clearly visible\n",
        ""
      ],
      "metadata": {
        "id": "7I6HBkZ5n5pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "def answer_with_rag(query: str,\n",
        "                   client=client,\n",
        "                   model_name=\"gemini-1.5-pro\",\n",
        "                   initial_results=10,\n",
        "                   max_context_passages=5,\n",
        "                   max_retries=3):\n",
        "    \"\"\"\n",
        "    Complete RAG (Retrieval-Augmented Generation) system that:\n",
        "    1. Retrieves relevant passages using vector search\n",
        "    2. Reranks them using Gemini\n",
        "    3. Generates a comprehensive answer based on the retrieved information\n",
        "\n",
        "    Args:\n",
        "        query (str): The user's question\n",
        "        client: Gemini API client (if None, will use global client)\n",
        "        model_name (str): Gemini model to use\n",
        "        initial_results (int): Number of initial results to get from vector search\n",
        "        max_context_passages (int): Maximum passages to include in the context\n",
        "        max_retries (int): Maximum number of retries on API failure\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            \"answer\": LLM-generated answer to the query,\n",
        "            \"sources\": List of sources with metadata and excerpts\n",
        "        }\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Step 1: Get initial search results from FAISS\n",
        "    search_results = load_index_and_search(query, top_k=initial_results)\n",
        "\n",
        "    if not search_results:\n",
        "        return {\n",
        "            \"answer\": \"I couldn't find any relevant information to answer your question.\",\n",
        "            \"sources\": []\n",
        "        }\n",
        "\n",
        "    # Step 2: Rerank the results using Gemini\n",
        "    reranked_results = rerank_with_gemini(\n",
        "        query=query,\n",
        "        search_results=search_results,\n",
        "        client=client,\n",
        "        model_name=model_name,\n",
        "        top_k=max_context_passages,\n",
        "        max_retries=max_retries\n",
        "    )\n",
        "\n",
        "    # Step 3: Format the context information from reranked results\n",
        "    context_passages = []\n",
        "    sources = []\n",
        "\n",
        "    for i, result in enumerate(reranked_results):\n",
        "        # Get the text chunk for context\n",
        "        text_chunk = result['text_chunk']\n",
        "        context_passages.append(f\"[{i+1}] {text_chunk}\")\n",
        "\n",
        "        # Store comprehensive source information including the excerpt\n",
        "        sources.append({\n",
        "            \"title\": result.get(\"title\", \"Unknown title\"),\n",
        "            \"source\": result.get(\"source\", \"Unknown source\"),\n",
        "            \"relevance_score\": result.get(\"relevance_score\", None),\n",
        "            \"explanation\": result.get(\"explanation\", None),\n",
        "            \"excerpt\": text_chunk  # Store the full text excerpt\n",
        "        })\n",
        "\n",
        "    context_text = \"\\n\\n\".join(context_passages)\n",
        "\n",
        "    # Step 4: Generate a comprehensive answer using Gemini\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert AI assistant that provides accurate, informative answers based on retrieved information.\n",
        "\n",
        "    USER QUERY: {query}\n",
        "\n",
        "    RELEVANT INFORMATION:\n",
        "    {context_text}\n",
        "\n",
        "    INSTRUCTIONS:\n",
        "    1. Answer the user's query thoroughly based on the provided information\n",
        "    2. Cite your sources using the corresponding numbers [1], [2], etc.\n",
        "    3. If the retrieved information doesn't fully answer the query, acknowledge the limitations\n",
        "    4. Present the information in a clear, well-structured format\n",
        "    5. Be objective and accurate - only use information from the provided passages\n",
        "    6. If the query cannot be answered with the retrieved information, state that clearly\n",
        "\n",
        "    YOUR ANSWER:\n",
        "    \"\"\"\n",
        "\n",
        "    # Function to make API call with retry logic\n",
        "    def generate_answer_with_retry(attempts=0):\n",
        "        try:\n",
        "            response = client.models.generate_content(\n",
        "                model=model_name,\n",
        "                contents=prompt,\n",
        "                config=types.GenerateContentConfig(\n",
        "                temperature=0.1,\n",
        "                response_mime_type=\"application/json\",\n",
        "                max_output_tokens=2048\n",
        "            ),\n",
        "            )\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            if attempts < max_retries:\n",
        "                wait_time = 2 ** attempts + random.uniform(0, 1)\n",
        "                print(f\"API error: {e}. Retrying in {wait_time:.1f} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "                return generate_answer_with_retry(attempts + 1)\n",
        "            else:\n",
        "                print(f\"Failed after {max_retries} attempts: {e}\")\n",
        "                return \"I encountered an error while trying to generate an answer. Please try again later.\"\n",
        "\n",
        "    # Generate the answer\n",
        "    answer = generate_answer_with_retry()\n",
        "\n",
        "    return {\n",
        "        \"answer\": answer,\n",
        "        \"sources\": sources\n",
        "           }\n",
        "\n",
        "# Enhanced display function with excerpts\n",
        "def display_rag_results(results):\n",
        "    \"\"\"\n",
        "    Display the RAG results in a readable format including source excerpts\n",
        "\n",
        "    Args:\n",
        "        results (dict): Results from answer_with_rag function\n",
        "    \"\"\"\n",
        "    print(\"=\" * 100)\n",
        "    print(\"ANSWER:\")\n",
        "    print(\"=\" * 100)\n",
        "    print(results[\"answer\"])\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"SOURCES WITH EXCERPTS:\")\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    for i, source in enumerate(results[\"sources\"]):\n",
        "        print(f\"[{i+1}] {source['source']}\")\n",
        "        print(f\" Title: {source['title']}\")\n",
        "        if source.get(\"relevance_score\"):\n",
        "            print(f\"    Relevance: {source['relevance_score']}/10\")\n",
        "        if source.get(\"explanation\"):\n",
        "            print(f\"    Explanation: {source['explanation']}\")\n",
        "\n",
        "        # Display the excerpt\n",
        "        print(\"\\n    EXCERPT:\")\n",
        "        print(f\"    {'-' * 80}\")\n",
        "        # Format the excerpt with proper indentation for readability\n",
        "        excerpt_lines = source['excerpt'].split('\\n')\n",
        "        for line in excerpt_lines:\n",
        "            print(f\"    {line}\")\n",
        "        print(f\"    {'-' * 80}\\n\")\n",
        "\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "# Example usage:\n",
        "answer = answer_with_rag(\"What is masking in transformer?\")\n",
        "display_rag_results(answer)\n",
        "\n"
      ],
      "metadata": {
        "id": "AR1POp6o3wdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d30015c-7f14-4e87-b37d-9df674f96b57"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "ANSWER:\n",
            "====================================================================================================\n",
            "{\"answer\": \"Masking in Transformers, specifically within the context of training, involves preventing the model from \\\"cheating\\\" by seeing the target word it's supposed to predict.  The provided texts describe the general architecture and mechanisms of the Transformer model, including positional encoding and the encoder-decoder structure [1, 2, 3, 4, 5]. However, they don't explicitly detail the concept of masking.  The text mentions shifting the decoder input to the right by one position to prevent the model from simply copying the input [5]. This shifting is related to the concept of masking, but it doesn't fully explain how masking works in the attention mechanism itself.  Therefore, while the provided texts offer some clues, they don't contain enough information to thoroughly explain masking in Transformers.\", \"sources\": [1, 2, 3, 4, 5]}\n",
            "\n",
            "====================================================================================================\n",
            "SOURCES WITH EXCERPTS:\n",
            "====================================================================================================\n",
            "[1] https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            " Title: What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            "    Relevance: 9/10\n",
            "    Explanation: This passage mentions BERT, which is a transformer-based model, and directly refers to the \"Attention is All You Need\" paper, which introduced the transformer model. It also discusses the encoder and decoder components of the transformer.\n",
            "\n",
            "    EXCERPT:\n",
            "    --------------------------------------------------------------------------------\n",
            "     paper prove architecture without rnn recurrent neural network improve result translation task task one improvement natural language task present team introduce bert bert deep bidirectional transformer language understanding exactly transformer image worth thousand word start figure attention need vaswani et al encoder left decoder right encoder decoder compose module stack top multiple time describe nx figure see module consist mainly attention fee forward layer input output target sentence fir\n",
            "    --------------------------------------------------------------------------------\n",
            "\n",
            "[2] https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            " Title: What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            "    Relevance: 8/10\n",
            "    Explanation: This passage discusses positional encoding, a crucial aspect of the transformer model that addresses the lack of sequential processing inherent in the architecture. It also mentions query, key, and value vectors, core components of the attention mechanism within transformers.\n",
            "\n",
            "    EXCERPT:\n",
            "    --------------------------------------------------------------------------------\n",
            "    st embed space since use string directly one slight important part model positional encoding different word since recurrent network remember sequence feed model need somehow give every sequence relative position since sequence depend order element position add embed representation vector word let close look attention brick model figure attention need vaswani et al let start left description complicate describe following equation q matrix contain query vector representation one word sequence k ke\n",
            "    --------------------------------------------------------------------------------\n",
            "\n",
            "[3] https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            " Title: What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            "    Relevance: 7/10\n",
            "    Explanation: This passage introduces the transformer model and mentions its effectiveness in NLP tasks. It also references the \"Attention is All You Need\" paper and discusses the encoder-decoder structure.\n",
            "\n",
            "    EXCERPT:\n",
            "    --------------------------------------------------------------------------------\n",
            "    transformer maxime follow min read jan listen share introduction transformer learning machine learn new deep learning model introduce increase rate sometimes hard keep track novelty say one particular neural network model prove especially effective common natural language processing task model call transformer make use several method mechanism introduce paper refer post offer detailed quantitative description part sequence sequence learning attention paper attention need describes transformer ca\n",
            "    --------------------------------------------------------------------------------\n",
            "\n",
            "[4] https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            " Title: What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            "    Relevance: 7/10\n",
            "    Explanation: This passage describes the encoder-decoder interaction within the transformer, including how the decoder input is shifted and used for training. This is relevant to understanding masking in the context of preventing the model from seeing future tokens.\n",
            "\n",
            "    EXCERPT:\n",
            "    --------------------------------------------------------------------------------\n",
            "    on decoder input sequence token first input encoder sequence new decoder sequence model take second element output put decoder input sequence repeat predict token mark end translation see need multiple run model translate sentence hope description make transformer architecture little bit clearer everybody start structure part transformer see transformer architecture know literature attention need author model extremely well language task let test transformer use case instead translation task let\n",
            "    --------------------------------------------------------------------------------\n",
            "\n",
            "[5] https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            " Title: What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            "    Relevance: 7/10\n",
            "    Explanation: This passage explains the purpose of shifting the decoder input, which is related to masking in the decoder to prevent cheating during training.\n",
            "\n",
            "    EXCERPT:\n",
            "    --------------------------------------------------------------------------------\n",
            "    ench german encoded input french sentence input decoder german sentence however decoder input shift right one position wait one reason want model learn copy decoder input training want learn give encoder sequence particular decoder sequence already see model predict next shift decoder sequence model learn simply copy decoder input since target position would decoder input thus shift decoder input one position model need predict target position see decoder sequence prevent model learn task fill f\n",
            "    --------------------------------------------------------------------------------\n",
            "\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "def answer_with_rag_cot(query: str,\n",
        "                    client=client,\n",
        "                    model_name=\"gemini-1.5-pro\",\n",
        "                    initial_results=10,\n",
        "                    max_context_passages=5,\n",
        "                    max_retries=3,\n",
        "                    include_cot=True):\n",
        "    \"\"\"\n",
        "    RAG system with Chain-of-Thought reasoning:\n",
        "    1. Retrieves relevant passages using vector search\n",
        "    2. Reranks them using Gemini\n",
        "    3. Applies Chain-of-Thought reasoning\n",
        "    4. Generates a comprehensive answer based on the retrieved information\n",
        "\n",
        "    Args:\n",
        "        query (str): The user's question\n",
        "        client: Gemini API client (if None, will use global client)\n",
        "        model_name (str): Gemini model to use\n",
        "        initial_results (int): Number of initial results to get from vector search\n",
        "        max_context_passages (int): Maximum passages to include in the context\n",
        "        max_retries (int): Maximum number of retries on API failure\n",
        "        include_cot (bool): Whether to include the chain-of-thought reasoning in output\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            \"answer\": LLM-generated answer to the query,\n",
        "            \"sources\": List of sources with metadata and excerpts,\n",
        "            \"cot_reasoning\": Chain-of-thought reasoning process (if include_cot=True)\n",
        "        }\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Step 1: Get initial search results from FAISS\n",
        "    search_results = load_index_and_search(query, top_k=initial_results)\n",
        "\n",
        "    if not search_results:\n",
        "        return {\n",
        "            \"answer\": \"I couldn't find any relevant information to answer your question.\",\n",
        "            \"sources\": [],\n",
        "            \"cot_reasoning\": \"No relevant information found.\"\n",
        "        }\n",
        "\n",
        "    # Step 2: Rerank the results using Gemini\n",
        "    reranked_results = rerank_with_gemini(\n",
        "        query=query,\n",
        "        search_results=search_results,\n",
        "        client=client,\n",
        "        model_name=model_name,\n",
        "        top_k=max_context_passages,\n",
        "        max_retries=max_retries\n",
        "    )\n",
        "\n",
        "    # Step 3: Format the context information from reranked results\n",
        "    context_passages = []\n",
        "    sources = []\n",
        "\n",
        "    for i, result in enumerate(reranked_results):\n",
        "        # Get the text chunk for context\n",
        "        text_chunk = result['text_chunk']\n",
        "        context_passages.append(f\"[{i+1}] {text_chunk}\")\n",
        "\n",
        "        # Store comprehensive source information including the excerpt\n",
        "        sources.append({\n",
        "            \"title\": result.get(\"title\", \"Unknown title\"),\n",
        "            \"source\": result.get(\"source\", \"Unknown source\"),\n",
        "            \"relevance_score\": result.get(\"relevance_score\", None),\n",
        "            \"explanation\": result.get(\"explanation\", None),\n",
        "            \"excerpt\": text_chunk  # Store the full text excerpt\n",
        "        })\n",
        "\n",
        "    context_text = \"\\n\\n\".join(context_passages)\n",
        "\n",
        "    # Step 4: Apply Chain-of-Thought reasoning\n",
        "    cot_prompt = f\"\"\"\n",
        "    You are an expert AI assistant that uses Chain-of-Thought reasoning to analyze information and answer questions.\n",
        "\n",
        "    USER QUERY: {query}\n",
        "\n",
        "    RELEVANT INFORMATION:\n",
        "    {context_text}\n",
        "\n",
        "    INSTRUCTIONS:\n",
        "    Perform a detailed Chain-of-Thought reasoning process to answer the query. Follow these steps:\n",
        "\n",
        "    Step 1: Analyze each retrieved context\n",
        "    - Summarize key information from each source\n",
        "    - Evaluate the relevance and reliability of each source\n",
        "    - Identify any contradictions or gaps between sources\n",
        "\n",
        "    Step 2: Identify key concepts relevant to the query\n",
        "    - Extract the main concepts, facts, and relationships\n",
        "    - Determine which information is most pertinent to answering the query\n",
        "    - Connect related pieces of information across different sources\n",
        "\n",
        "    Step 3: Synthesize a comprehensive answer\n",
        "    - Integrate information from all relevant sources\n",
        "    - Address the query directly and completely\n",
        "    - Acknowledge any limitations or uncertainties\n",
        "\n",
        "    Format your response as a detailed reasoning process through these steps. Be explicit about your reasoning.\n",
        "    Use exact citations to the source materials using [1], [2], etc.\n",
        "\n",
        "    YOUR CHAIN-OF-THOUGHT REASONING:\n",
        "    \"\"\"\n",
        "\n",
        "    # Function to make API call with retry logic\n",
        "    def generate_cot_with_retry(attempts=0):\n",
        "        try:\n",
        "            response = client.models.generate_content(\n",
        "                model=model_name,\n",
        "                contents=cot_prompt,\n",
        "                config=types.GenerateContentConfig(\n",
        "                temperature=0.1,\n",
        "                response_mime_type=\"application/json\",\n",
        "                max_output_tokens=2048\n",
        "            ),\n",
        "            )\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            if attempts < max_retries:\n",
        "                wait_time = 2 ** attempts + random.uniform(0, 1)\n",
        "                print(f\"API error: {e}. Retrying in {wait_time:.1f} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "                return generate_cot_with_retry(attempts + 1)\n",
        "            else:\n",
        "                print(f\"Failed after {max_retries} attempts: {e}\")\n",
        "                return \"I encountered an error while trying to generate the chain-of-thought reasoning.\"\n",
        "\n",
        "    # Generate the chain-of-thought reasoning\n",
        "    cot_reasoning = generate_cot_with_retry()\n",
        "\n",
        "    # Step 5: Generate final answer based on CoT reasoning\n",
        "    answer_prompt = f\"\"\"\n",
        "    You are an expert AI assistant that provides accurate, informative answers based on retrieved information.\n",
        "\n",
        "    USER QUERY: {query}\n",
        "\n",
        "    You've already performed a detailed chain-of-thought reasoning process:\n",
        "\n",
        "    {cot_reasoning}\n",
        "\n",
        "    Now, provide a clear, concise, and comprehensive answer to the user's query based on your reasoning.\n",
        "    - Cite your sources using the corresponding numbers [1], [2], etc.\n",
        "    - Focus on being accurate, informative, and helpful\n",
        "    - Present the information in a well-structured format\n",
        "    - Be direct and to the point\n",
        "\n",
        "    YOUR FINAL ANSWER:\n",
        "    \"\"\"\n",
        "\n",
        "    def generate_answer_with_retry(attempts=0):\n",
        "        try:\n",
        "            response = client.models.generate_content(\n",
        "                model=model_name,\n",
        "                contents=answer_prompt,\n",
        "                config=types.GenerateContentConfig(\n",
        "                temperature=0.1,\n",
        "                response_mime_type=\"application/json\",\n",
        "                max_output_tokens=2048\n",
        "            ),\n",
        "            )\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            if attempts < max_retries:\n",
        "                wait_time = 2 ** attempts + random.uniform(0, 1)\n",
        "                print(f\"API error: {e}. Retrying in {wait_time:.1f} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "                return generate_answer_with_retry(attempts + 1)\n",
        "            else:\n",
        "                print(f\"Failed after {max_retries} attempts: {e}\")\n",
        "                return \"I encountered an error while trying to generate an answer. Please try again later.\"\n",
        "\n",
        "    # Generate the final answer\n",
        "    answer = generate_answer_with_retry()\n",
        "\n",
        "    result = {\n",
        "        \"answer\": answer,\n",
        "        \"sources\": sources\n",
        "           }\n",
        "\n",
        "    # Include CoT reasoning if requested\n",
        "    if include_cot:\n",
        "        result[\"cot_reasoning\"] = cot_reasoning\n",
        "\n",
        "    return result\n",
        "\n",
        "# Enhanced display function with chain-of-thought reasoning\n",
        "def display_rag_cot_results(results):\n",
        "    \"\"\"\n",
        "    Display the RAG results with Chain-of-Thought reasoning in a readable format\n",
        "\n",
        "    Args:\n",
        "        results (dict): Results from answer_with_rag_cot function\n",
        "    \"\"\"\n",
        "    print(\"=\" * 100)\n",
        "    print(\"ANSWER:\")\n",
        "    print(\"=\" * 100)\n",
        "    print(results[\"answer\"])\n",
        "\n",
        "    if \"cot_reasoning\" in results:\n",
        "        print(\"\\n\" + \"=\" * 100)\n",
        "        print(\"CHAIN-OF-THOUGHT REASONING:\")\n",
        "        print(\"=\" * 100)\n",
        "        print(results[\"cot_reasoning\"])\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"SOURCES WITH EXCERPTS:\")\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    for i, source in enumerate(results[\"sources\"]):\n",
        "        print(f\"[{i+1}] {source['source']}\")\n",
        "        print(f\" Title: {source['title']}\")\n",
        "        if source.get(\"relevance_score\"):\n",
        "            print(f\"    Relevance: {source['relevance_score']}/10\")\n",
        "        if source.get(\"explanation\"):\n",
        "            print(f\"    Explanation: {source['explanation']}\")\n",
        "\n",
        "        # Display the excerpt\n",
        "        print(\"\\n    EXCERPT:\")\n",
        "        print(f\"    {'-' * 80}\")\n",
        "        # Format the excerpt with proper indentation for readability\n",
        "        excerpt_lines = source['excerpt'].split('\\n')\n",
        "        for line in excerpt_lines:\n",
        "            print(f\"    {line}\")\n",
        "        print(f\"    {'-' * 80}\\n\")\n",
        "\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "results = answer_with_rag_cot(\"What are the advantages and limitations of transformer models?\")\n",
        "display_rag_cot_results(results)"
      ],
      "metadata": {
        "id": "rf_yY1guZRQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a803a105-3b78-420a-a582-09ce7ab87ae7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "ANSWER:\n",
            "====================================================================================================\n",
            "{\"Advantages\": [\"Parallelizable architecture enabling efficient training and inference, especially with large datasets [2, 3]\", \"Excellent at capturing long-range dependencies in sequences due to the attention mechanism [2, 4]\", \"Reduced need for manual feature engineering [1]\"], \"Limitations\": [\"Computationally intensive training, particularly for very large datasets [1]\", \"Specific limitations beyond training complexity are not detailed in the provided context\"], \"Overall\": \"Transformer models offer significant advantages over traditional RNNs like LSTMs and GRUs, especially in terms of efficiency and ability to handle long sequences. However, training can be resource-intensive, and further research is needed to fully explore their limitations.\"}\n",
            "\n",
            "====================================================================================================\n",
            "CHAIN-OF-THOUGHT REASONING:\n",
            "====================================================================================================\n",
            "{\"Step 1: Analyze each retrieved context\": [{\"Source\": \"[1]\", \"Summary\": \"RNNs, LSTMs, and GRUs have limitations in training complexity and potential effectiveness issues.  Manual feature engineering is reduced due to relevant feature direct data. Despite strong performance, there's room for improvement.\", \"Relevance\": \"High - Discusses limitations of RNNs and potential improvements, which are relevant to transformer models as a potential alternative.\", \"Reliability\": \"Medium - The source mentions limitations and potential improvements but lacks specific details.\", \"Contradictions/Gaps\": \"None identified\"}, {\"Source\": \"[2]\", \"Summary\": \"Transformers outperform RNNs in many sequential tasks due to parallelizable architecture. Attention mechanisms could improve RNN performance. Future work could incorporate transformers for customer behavior prediction.\", \"Relevance\": \"High - Directly compares transformers and RNNs, highlighting the advantages of transformers.\", \"Reliability\": \"Medium - Mentions the benefits of transformers but lacks specific examples or details.\", \"Contradictions/Gaps\": \"None identified\"}, {\"Source\": \"[3]\", \"Summary\": \"Transformers are highly parallelizable and efficient at capturing dependencies in sequences. Future work could explore hybrid models combining traditional methods and transformers.\", \"Relevance\": \"High - Reinforces the advantages of transformers and suggests potential future research directions.\", \"Reliability\": \"Medium - Similar to [2], it mentions advantages without specific examples.\", \"Contradictions/Gaps\": \"None identified\"}, {\"Source\": \"[4]\", \"Summary\": \"One limitation of RNNs is their step-by-step processing. Attention mechanisms could improve their performance. Transformer architecture has revolutionized NLP.\", \"Relevance\": \"High - Highlights a key limitation of RNNs and mentions the impact of transformers on NLP.\", \"Reliability\": \"Medium - Provides a general overview but lacks in-depth analysis.\", \"Contradictions/Gaps\": \"None identified\"}, {\"Source\": \"[5]\", \"Summary\": \"The transformer architecture uses an encoder-decoder structure and differs from RNNs like LSTMs and GRUs. It offers a different approach to capturing dependencies in sequences.\", \"Relevance\": \"High - Explains the core architecture of transformers and how they differ from RNNs.\", \"Reliability\": \"Medium - Provides a high-level description of the architecture but lacks technical details.\", \"Contradictions/Gaps\": \"None identified\"}], \"Step 2: Identify key concepts relevant to the query\": {\"Key Concepts\": [\"Transformer models\", \"RNNs (LSTMs, GRUs)\", \"Advantages of transformers\", \"Limitations of transformers\", \"Attention mechanism\", \"Parallelization\", \"Sequence processing\", \"Feature engineering\"], \"Relevant Information\": \"Transformers offer advantages in parallelization and sequence processing compared to RNNs. They reduce the need for manual feature engineering. Attention mechanisms are a key component of transformers.  The training complexity of transformers, especially with large datasets, is a potential limitation.\", \"Connections\": \"Sources [1, 2, 4, 5] highlight the limitations of RNNs and how transformers address some of these limitations. Sources [2, 3] emphasize the parallelization advantage of transformers. Source [4] connects attention mechanisms to improved performance.\"}, \"Step 3: Synthesize a comprehensive answer\": {\"Answer\": \"Transformer models offer several advantages over traditional recurrent neural networks (RNNs) like LSTMs and GRUs. Their parallelizable architecture allows for more efficient training and inference, especially with large datasets [2, 3].  They excel at capturing long-range dependencies in sequences due to the attention mechanism, which allows the model to focus on the most relevant parts of the input [2, 4].  Additionally, transformers reduce the need for manual feature engineering [1]. However, training these models can still be computationally intensive, particularly for very large datasets [1]. While sources suggest potential improvements and future research directions like hybrid models [3], specific limitations of transformer models aren't detailed in the provided context.  The provided text focuses on the relative advantages compared to RNNs and LSTMs, highlighting the architectural differences and efficiency gains [5]. Further research is needed to fully understand the limitations of transformer models in different contexts.\", \"Limitations/Uncertainties\": \"The provided texts do not offer a comprehensive discussion of transformer limitations.  More information is needed to provide a complete picture.\"}}\n",
            "\n",
            "====================================================================================================\n",
            "SOURCES WITH EXCERPTS:\n",
            "====================================================================================================\n",
            "[1] https://medium.com/analytics-vidhya/what-is-rnn-a157d903a88\n",
            " Title: Recurrent Neural Networks — Complete and In-depth | by Tejas T A | Analytics Vidhya | Medium\n",
            "    Relevance: 8/10\n",
            "    Explanation: Discusses limitations of RNNs (including LSTMs and GRUs) like training complexity and computational intensiveness, and mentions their strengths in sequential tasks, implicitly comparing them to transformers which are known for better parallelization.\n",
            "\n",
            "    EXCERPT:\n",
            "    --------------------------------------------------------------------------------\n",
            "     relevant feature directly data reduce need manual feature engineering discussion limitation potential improvement despite strong performance rnns lstms grus limitation could impact effectiveness certain context training complexity training model computationally intensive particularly large datasets rnns especially lstms grus high training complexity compare traditional model due backpropagation time bptt algorithm lead longer train time case may require computational resource gradient although \n",
            "    --------------------------------------------------------------------------------\n",
            "\n",
            "[2] https://medium.com/analytics-vidhya/what-is-rnn-a157d903a88\n",
            " Title: Recurrent Neural Networks — Complete and In-depth | by Tejas T A | Analytics Vidhya | Medium\n",
            "    Relevance: 7/10\n",
            "    Explanation: Explains potential improvements of incorporating attention mechanisms (which are core to transformers) into RNNs and suggests future work using transformers for customer behavior prediction, highlighting their efficiency.\n",
            "\n",
            "    EXCERPT:\n",
            "    --------------------------------------------------------------------------------\n",
            "    que like dropout employ mitigate risk remain challenge potential improvement attention mechanism incorporate attention mechanism could improve performance rnns allow model focus specific part sequence relevant prediction would enhance ability capture dependency effectively transformer model transformer show outperform rnns many sequential task due parallelizable architecture mechanism future work incorporate transformer customer behavior prediction could improve accuracy training efficiency data\n",
            "    --------------------------------------------------------------------------------\n",
            "\n",
            "[3] https://medium.com/analytics-vidhya/what-is-rnn-a157d903a88\n",
            " Title: Recurrent Neural Networks — Complete and In-depth | by Tejas T A | Analytics Vidhya | Medium\n",
            "    Relevance: 7/10\n",
            "    Explanation: Discusses the advantages of transformers (parallelization, efficient dependency capture) for customer behavior prediction and suggests exploring hybrid models combining traditional methods and transformers.\n",
            "\n",
            "    EXCERPT:\n",
            "    --------------------------------------------------------------------------------\n",
            "    rocessing could offer significant improvement customer behavior prediction transformer highly parallelizable capture dependency sequence efficiently rnns test transformer customer behavior prediction task could reveal new opportunity enhance predictive accuracy reduce train time hybrid model future work could explore combine strength traditional machine learning model approach example hybrid model could use traditional method initial feature extraction rnns sequence modeling leverage strength ap\n",
            "    --------------------------------------------------------------------------------\n",
            "\n",
            "[4] https://medium.com/analytics-vidhya/what-is-rnn-a157d903a88\n",
            " Title: Recurrent Neural Networks — Complete and In-depth | by Tejas T A | Analytics Vidhya | Medium\n",
            "    Relevance: 6/10\n",
            "    Explanation: Mentions the \"attention is all you need\" paper, which introduced the transformer model, and describes the encoder-decoder structure, a key aspect of transformers.\n",
            "\n",
            "    EXCERPT:\n",
            "    --------------------------------------------------------------------------------\n",
            "    ovement future exploration identify incorporating attention mechanism one key limitation rnns even advanced form lstm gru reliance processing sequence step step dilute importance critical time step integrate attention mechanism model focus relevant part sequence potentially improve performance attention allow model weigh different part input sequence differently give high importance critical input prediction task explore transformer model transformer architecture revolutionize natural language p\n",
            "    --------------------------------------------------------------------------------\n",
            "\n",
            "[5] https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
            " Title: What is a Transformer?. An Introduction to Transformers and… | by Maxime | Inside Machine learning | Medium\n",
            "    Relevance: 6/10\n",
            "    Explanation: Mentions the \"attention is all you need\" paper and how transformers differ from LSTM and GRU models, highlighting the shift away from recurrent networks.\n",
            "\n",
            "    EXCERPT:\n",
            "    --------------------------------------------------------------------------------\n",
            "    ion see article scientific approach one provide read different approach model great paper call effective approach neural machine translation part transformer paper attention need introduces novel architecture call transformer title indicate use saw earlier like lstm transformer architecture transform one sequence another one help two part encoder decoder differ previously model imply recurrent network gru lstm recurrent network one best way capture timely dependency sequence however team present\n",
            "    --------------------------------------------------------------------------------\n",
            "\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a9DjXUhAJEO7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}